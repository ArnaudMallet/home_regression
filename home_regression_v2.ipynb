{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "samples_submission_csv = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtf_description = train_csv.describe()\n",
    "dtf_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.04995836802665"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use mean and column to replace the NA or field that are NAN instead to put thm to 0\n",
    "dtf_description.loc['mean']['LotFrontage']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtExposure       38\n",
       "BsmtFinType1       37\n",
       "BsmtFinSF1          0\n",
       "BsmtFinType2       38\n",
       "BsmtFinSF2          0\n",
       "BsmtUnfSF           0\n",
       "TotalBsmtSF         0\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          1\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        0\n",
       "BsmtHalfBath        0\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_data(data, perc=0.7):\n",
    "    return data.head(int(len(data)*(perc)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file_data, csv_file_test, id_col, target_col, data='train'):\n",
    "        self.data_train= pd.read_csv(csv_file_data)\n",
    "        self.data_test = pd.read_csv(csv_file_test)\n",
    "        self.id        = id_col\n",
    "        self.target    = target_col\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data == 'train':\n",
    "            return len(self.data_train)\n",
    "        else:\n",
    "            return len(self.data_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # remove the target column\n",
    "        train_wo_SP = self.data_train.drop(self.target, axis='columns')\n",
    "        # concat train and test features to have the same number of columns one the dummies features appear\n",
    "        all_features = pd.concat([train_wo_SP, self.data_test], keys=[\"train\", \"test\"])\n",
    "        # Normalize the numerical features\n",
    "        numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "        all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "        # creathe the dummies for train and test set\n",
    "        all_features_dummies = pd.get_dummies(all_features)\n",
    "        all_features_dummies = all_features_dummies.fillna(0)\n",
    "        #print(all_features_dummies)\n",
    "        \n",
    "        # creation of the label of train dataset\n",
    "        train_label1 = train_csv['Id']\n",
    "        train_label2 = train_csv['SalePrice']\n",
    "        train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "        train_label['Id'] = train_label1\n",
    "        train_label['SalePrice'] = train_label2\n",
    "\n",
    "        #Split Data - creation of the Validation dataset\n",
    "        train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "        valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "        \n",
    "        #Split label - creation of the validation labelset\n",
    "        label_train = split_train_valid_data(train_label)\n",
    "        label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "         \n",
    "        # creation of the test data set\n",
    "        test_data = all_features_dummies.loc['test']\n",
    "        \n",
    "        # creation of an Empty label test\n",
    "        label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "        \n",
    "        train_data = train_data.astype(np.float32)\n",
    "        valid_data = valid_data.astype(np.float32)\n",
    "        test_data = test_data.astype(np.float32)\n",
    "        \n",
    "        # remove 'ID' columns - data\n",
    "        train_data = train_data.drop(['Id'], axis=1)\n",
    "        valid_data = valid_data.drop(['Id'],axis=1)\n",
    "        test_data = test_data.drop(['Id'], axis=1)\n",
    "        \n",
    "        # remove 'ID' column - label\n",
    "        label_train = label_train.drop(['Id'], axis=1)\n",
    "        label_valid = label_valid.drop(['Id'], axis=1)\n",
    "            \n",
    "        # data preparation\n",
    "        if self.data == 'train':\n",
    "            use_data = train_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'valid':\n",
    "            use_data = valid_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'test':\n",
    "            use_data = test_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "            \n",
    "        # label preparation\n",
    "        if self.data == 'train':\n",
    "            label_data = label_train.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'valid':\n",
    "            label_data = label_valid.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'test':\n",
    "            label_data = label_test.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        \n",
    "        return use_data, label_data\n",
    "\n",
    "params = {\n",
    "    'id_col':'Id',  \n",
    "    'target_col': ['SalePrice'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataset = {x: CustomDataset(csv_file_data=\"train.csv\" , \n",
    "                                   csv_file_test=\"test.csv\", \n",
    "                                   **params, \n",
    "                                   data='train' if x == 'train'\n",
    "                                   else 'valid' if x =='valid'\n",
    "                                   else 'test')\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader = {x: torch.utils.data.DataLoader(data_dataset[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "tensor_dt = data_dataset['train'].__getitem__(1)\n",
    "print(len(tensor_dt[0][0]))\n",
    "\n",
    "print(type(tensor_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([1021, 288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([1021, 288])\n",
      "\n",
      "Target at the first row:  tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: torch.Size([1021, 1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 1021, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1021, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "\n",
    "img, lab_target = data_dataset['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-71c0f3bff8da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_loader\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mnext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    344\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 346\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     42\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-911cefd7febe>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Normalize the numerical features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mall_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m# creathe the dummies for train and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mall_features_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[0;32m   6911\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6912\u001b[0m         )\n\u001b[1;32m-> 6913\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6914\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6915\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 186\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m         \u001b[1;31m# compute the result using the series generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;31m# wrap results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m                     \u001b[0mresults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-911cefd7febe>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m# Normalize the numerical features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mnumeric_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtypes\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'object'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mall_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnumeric_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m         \u001b[1;31m# creathe the dummies for train and test set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mall_features_dummies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_dummies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mstat_func\u001b[1;34m(self, axis, skipna, level, ddof, numeric_only, **kwargs)\u001b[0m\n\u001b[0;32m  11638\u001b[0m             )\n\u001b[0;32m  11639\u001b[0m         return self._reduce(\n\u001b[1;32m> 11640\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumeric_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnumeric_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m  11641\u001b[0m         )\n\u001b[0;32m  11642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m_reduce\u001b[1;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[0;32m   4085\u001b[0m                 )\n\u001b[0;32m   4086\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4087\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4088\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4089\u001b[0m         \u001b[1;31m# TODO(EA) dispatch to Index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    118\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanstd\u001b[1;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m     \"\"\"\n\u001b[1;32m--> 711\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnanvar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mddof\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    712\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrap_results\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    713\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36m_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrstate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minvalid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"ignore\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[1;31m# we want to transform an object array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mf\u001b[1;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[0;32m    118\u001b[0m                         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskipna\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskipna\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\pandas\\core\\nanops.py\u001b[0m in \u001b[0;36mnanvar\u001b[1;34m(values, axis, skipna, ddof, mask)\u001b[0m\n\u001b[0;32m    772\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mputmask\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msqr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 774\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0md\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m     \u001b[1;31m# Return variance as np.float64 (the datatype used in the accumulator),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\numpy\\core\\_methods.py\u001b[0m in \u001b[0;36m_sum\u001b[1;34m(a, axis, dtype, out, keepdims, initial)\u001b[0m\n\u001b[0;32m     34\u001b[0m def _sum(a, axis=None, dtype=None, out=None, keepdims=False,\n\u001b[0;32m     35\u001b[0m          initial=_NoValue):\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mumr_sum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m def _prod(a, axis=None, dtype=None, out=None, keepdims=False,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(data_loader['train']):\n",
    "    print(len(target))\n",
    "    next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        \n",
    "        # linear layer (330 -> 755001)\n",
    "        self.fc1 = nn.Linear(288, 250)\n",
    "        \n",
    "        # linear layer (500 -> 250)\n",
    "        self.fc2 = nn.Linear(250, 125)\n",
    "        \n",
    "        # linear layer (250 -> 125)\n",
    "        self.fc3 = nn.Linear(125, 75)\n",
    "        \n",
    "        # linear layer (125 -> 1)\n",
    "        self.fc4 = nn.Linear(75, 755001)\n",
    "        \n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.175)\n",
    "        \n",
    "        # LogSoftmax\n",
    "        self.LSM = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h2\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h3\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h4\n",
    "        x = self.fc4(x)\n",
    "        x = self.LSM(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_HR = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_patho.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=288, out_features=250, bias=True)\n",
       "  (fc2): Linear(in_features=250, out_features=125, bias=True)\n",
       "  (fc3): Linear(in_features=125, out_features=75, bias=True)\n",
       "  (fc4): Linear(in_features=75, out_features=755001, bias=True)\n",
       "  (dropout): Dropout(p=0.175, inplace=False)\n",
       "  (LSM): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.SGD(model_HR.parameters(), lr=0.01, momentum = 0.9)\n",
    "\n",
    "VERSION = 'Test_version'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amallet\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 13.522294 \tValidation Loss: 13.504157 \tTime since the beginning 1.8 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (inf --> 13.504157).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 13.351097 \tValidation Loss: 12.840249 \tTime since the beginning 3.6 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (13.504157 --> 12.840249).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 11.050257 \tValidation Loss: 10.242091 \tTime since the beginning 5.4 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (12.840249 --> 10.242091).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 8.973546 \tValidation Loss: 9.621675 \tTime since the beginning 7.1 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (10.242091 --> 9.621675).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 8.022004 \tValidation Loss: 9.274684 \tTime since the beginning 8.8 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.621675 --> 9.274684).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 7.492919 \tValidation Loss: 9.354582 \tTime since the beginning 10.5 min \tLearning rate: 0.010000 \n",
      "Epoch: 7 \tTraining Loss: 7.194787 \tValidation Loss: 9.306846 \tTime since the beginning 12.2 min \tLearning rate: 0.010000 \n",
      "Epoch: 8 \tTraining Loss: 6.882911 \tValidation Loss: 9.059667 \tTime since the beginning 13.9 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.274684 --> 9.059667).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 6.668493 \tValidation Loss: 9.141168 \tTime since the beginning 15.6 min \tLearning rate: 0.010000 \n",
      "Epoch: 10 \tTraining Loss: 6.608951 \tValidation Loss: 8.957096 \tTime since the beginning 17.2 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.059667 --> 8.957096).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_res = train(10, data_loader, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 30834240840 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-1dbb465258fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_HR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-17-77c27900883e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-0bbf1ced8ea9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m#h4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 30834240840 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "model_res = train(10, data_loader2, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter_test = iter(data_loader['test'])\n",
    "print('data_iter\\n',dataiter_test)\n",
    "data_test = dataiter_test.next()\n",
    "data_test_data = data_test[0]\n",
    "print('image test data',data_test_data)\n",
    "\n",
    "model_test = model_HR\n",
    "model_test.load_state_dict(torch.load(VERSION))\n",
    "model_test = model_test.eval()\n",
    "\n",
    "\n",
    "out_fwd = model_test.forward(data_test_data)\n",
    "print('Result preditcion model on dataset:\\n {}\\n'.format(out_fwd))\n",
    "probs = torch.exp(out_fwd)\n",
    "print('probs\\n', probs)\n",
    "print(probs.max())\n",
    "print(probs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
