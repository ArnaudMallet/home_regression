{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "samples_submission_csv = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtExposure       38\n",
       "BsmtFinType1       37\n",
       "BsmtFinSF1          0\n",
       "BsmtFinType2       38\n",
       "BsmtFinSF2          0\n",
       "BsmtUnfSF           0\n",
       "TotalBsmtSF         0\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          1\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        0\n",
       "BsmtHalfBath        0\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_data(data, perc=0.7):\n",
    "    return data.head(int(len(data)*(perc)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id             1460\n",
      "SalePrice    755000\n",
      "dtype: int64\n",
      "before\n",
      "(1021, 289)\n",
      "(439, 289)\n",
      "(1021, 2)\n",
      "(439, 2)\n",
      "(1459, 289)\n",
      "(1459, 1)\n",
      "after\n",
      "(1021, 288)\n",
      "(439, 288)\n",
      "(1021, 1)\n",
      "(439, 1)\n",
      "(1459, 288)\n",
      "(1459, 1)\n"
     ]
    }
   ],
   "source": [
    "train_wo_SP = train_csv.drop(['SalePrice'], axis='columns')\n",
    "#print(train_wo_SP)\n",
    "# concat train and test features to have the same number of columns one the dummies features appear\n",
    "all_features = pd.concat([train_wo_SP, test_csv], keys=[\"train\", \"test\"])\n",
    "#print(all_features)\n",
    "# Normalize the numerical features\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "# creathe the dummies for train and test set\n",
    "all_features_dummies = pd.get_dummies(all_features)\n",
    "#print(all_features_dummies)\n",
    "\n",
    "# creation of the label of train dataset\n",
    "train_label1 = train_csv['Id']\n",
    "train_label2 = train_csv['SalePrice']\n",
    "train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "train_label['Id'] = train_label1\n",
    "train_label['SalePrice'] = train_label2\n",
    "print(train_label.max())\n",
    "\n",
    "#Split Data - creation of the Validation dataset\n",
    "train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "\n",
    "#Split label - creation of the validation labelset\n",
    "label_train = split_train_valid_data(train_label)\n",
    "label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "\n",
    "# creation of the test data set\n",
    "test_data = all_features_dummies.loc['test']\n",
    "\n",
    "# creation of an Empty label test\n",
    "label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "\n",
    "print('before')\n",
    "\n",
    "train_data = train_data.astype(np.float32)\n",
    "valid_data = valid_data.astype(np.float32)\n",
    "test_data = test_data.astype(np.float32)\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(label_train.shape)\n",
    "print(label_valid.shape)\n",
    "print(test_data.shape)\n",
    "print(label_test.shape)\n",
    "\n",
    "# remove 'ID' columns - data\n",
    "train_data = train_data.drop(['Id'], axis=1)\n",
    "train_data = train_data.fillna(0)\n",
    "valid_data = valid_data.drop(['Id'],axis=1)\n",
    "valid_data = valid_data.fillna(0)\n",
    "test_data = test_data.drop(['Id'], axis=1)\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "# remove 'ID' column - label\n",
    "label_train = label_train.drop(['Id'], axis=1)\n",
    "label_valid = label_valid.drop(['Id'], axis=1)\n",
    "\n",
    "print('after')\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(label_train.shape)\n",
    "print(label_valid.shape)\n",
    "print(test_data.shape)\n",
    "print(label_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "class PrepareData(Dataset):\n",
    "\n",
    "    def __init__(self, In, Out):\n",
    "        if not torch.is_tensor(In):\n",
    "            In = In.to_numpy()\n",
    "            self.In = torch.from_numpy(In)\n",
    "        if not torch.is_tensor(Out):\n",
    "            Out = Out.to_numpy()\n",
    "            self.Out = torch.from_numpy(Out)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.In)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.In[idx], self.Out[idx]\n",
    "        \n",
    "\n",
    "\n",
    "data_dataset = {x: PrepareData(In=train_data if x == 'train'\n",
    "                               else valid_data if x =='valid'\n",
    "                               else test_data, \n",
    "                               Out=label_train if x == 'train'\n",
    "                               else label_valid if x == 'valid'\n",
    "                               else label_test)\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader = {x: torch.utils.data.DataLoader(data_dataset[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([288])\n",
      "\n",
      "Target at the first row:  tensor([208500])\n",
      "Target format at the first row: tensor([208500])\n",
      "Target format at the first row: torch.Size([1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "img, lab_target = data_dataset['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file_data, csv_file_test, id_col, target_col, data='train'):\n",
    "        self.data_train= pd.read_csv(csv_file_data)\n",
    "        self.data_test = pd.read_csv(csv_file_test)\n",
    "        self.id        = id_col\n",
    "        self.target    = target_col\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data == 'train':\n",
    "            return len(self.data_train)\n",
    "        else:\n",
    "            return len(self.data_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # remove the target column\n",
    "        train_wo_SP = self.data_train.drop(self.target, axis='columns')\n",
    "        # concat train and test features to have the same number of columns one the dummies features appear\n",
    "        all_features = pd.concat([train_wo_SP, self.data_test], keys=[\"train\", \"test\"])\n",
    "        # Normalize the numerical features\n",
    "        numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "        all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "        # creathe the dummies for train and test set\n",
    "        all_features_dummies = pd.get_dummies(all_features)\n",
    "        \n",
    "        # creation of the label of train dataset\n",
    "        train_label1 = train_csv['Id']\n",
    "        train_label2 = train_csv['SalePrice']\n",
    "        train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "        train_label['Id'] = train_label1\n",
    "        train_label['SalePrice'] = train_label2\n",
    "\n",
    "        #Split Data - creation of the Validation dataset\n",
    "        train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "        valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "        #Split label - creation of the validation labelset\n",
    "        label_train = split_train_valid_data(train_label)\n",
    "        label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "         \n",
    "        # creation of the test data set\n",
    "        test_data = all_features_dummies.loc['test']\n",
    "        \n",
    "        # creation of an Empty label test\n",
    "        label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "        \n",
    "        train_data = train_data.astype(np.float32)\n",
    "        valid_data = valid_data.astype(np.float32)\n",
    "        test_data = test_data.astype(np.float32)\n",
    "        \n",
    "        # remove 'ID' columns - data\n",
    "        train_data = train_data.drop(['Id'], axis=1)\n",
    "        valid_data = valid_data.drop(['Id'],axis=1)\n",
    "        test_data = test_data.drop(['Id'], axis=1)\n",
    "        \n",
    "        # remove 'ID' column - label\n",
    "        label_train = label_train.drop(['Id'], axis=1)\n",
    "        label_valid = label_valid.drop(['Id'], axis=1)\n",
    "            \n",
    "        # data preparation\n",
    "        if self.data == 'train':\n",
    "            use_data = train_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'valid':\n",
    "            use_data = valid_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'test':\n",
    "            use_data = test_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "            \n",
    "        # label preparation\n",
    "        if self.data == 'train':\n",
    "            label_data = label_train.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'valid':\n",
    "            label_data = label_valid.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'test':\n",
    "            label_data = label_test.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        \n",
    "        return use_data, label_data\n",
    "\n",
    "params = {\n",
    "    'id_col':'Id',  \n",
    "    'target_col': ['SalePrice'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataset2 = {x: CustomDataset(csv_file_data=\"train.csv\" , \n",
    "                                   csv_file_test=\"test.csv\", \n",
    "                                   **params, \n",
    "                                   data='train' if x == 'train'\n",
    "                                   else 'valid' if x =='valid'\n",
    "                                   else 'test')\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader2 = {x: torch.utils.data.DataLoader(data_dataset2[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([1021, 288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([1021, 288])\n",
      "\n",
      "Target at the first row:  tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: torch.Size([1021, 1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 1021, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1021, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "img, lab_target = data_dataset2['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader2['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        [140000],\n",
      "        [250000],\n",
      "        [143000],\n",
      "        [307000],\n",
      "        [200000],\n",
      "        [129900],\n",
      "        [118000]])\n",
      "tensor([[129500],\n",
      "        [345000],\n",
      "        [144000],\n",
      "        [279500],\n",
      "        [157000],\n",
      "        [132000],\n",
      "        [149000],\n",
      "        [ 90000],\n",
      "        [159000],\n",
      "        [139000]])\n",
      "tensor([[325300],\n",
      "        [139400],\n",
      "        [230000],\n",
      "        [129900],\n",
      "        [154000],\n",
      "        [256300],\n",
      "        [134800],\n",
      "        [306000],\n",
      "        [207500],\n",
      "        [ 68500]])\n",
      "tensor([[ 40000],\n",
      "        [149350],\n",
      "        [179900],\n",
      "        [165500],\n",
      "        [277500],\n",
      "        [309000],\n",
      "        [145000],\n",
      "        [153000],\n",
      "        [109000],\n",
      "        [ 82000]])\n",
      "tensor([[160000],\n",
      "        [170000],\n",
      "        [144000],\n",
      "        [130250],\n",
      "        [141000],\n",
      "        [319900],\n",
      "        [239686],\n",
      "        [249700],\n",
      "        [113000],\n",
      "        [127000]])\n",
      "tensor([[177000],\n",
      "        [114500],\n",
      "        [110000],\n",
      "        [385000],\n",
      "        [130000],\n",
      "        [180500],\n",
      "        [172500],\n",
      "        [196500],\n",
      "        [438780],\n",
      "        [124900]])\n",
      "tensor([[158000],\n",
      "        [101000],\n",
      "        [202500],\n",
      "        [140000],\n",
      "        [219500],\n",
      "        [317000],\n",
      "        [180000],\n",
      "        [226000],\n",
      "        [ 80000],\n",
      "        [225000]])\n",
      "tensor([[244000],\n",
      "        [129500],\n",
      "        [185000],\n",
      "        [144900],\n",
      "        [107400],\n",
      "        [ 91000],\n",
      "        [135750],\n",
      "        [127000],\n",
      "        [136500],\n",
      "        [110000]])\n",
      "tensor([[193500],\n",
      "        [153500],\n",
      "        [245000],\n",
      "        [126500],\n",
      "        [168500],\n",
      "        [260000],\n",
      "        [174000],\n",
      "        [164500],\n",
      "        [ 85000],\n",
      "        [123600]])\n",
      "tensor([[109900],\n",
      "        [ 98600],\n",
      "        [163500],\n",
      "        [133900],\n",
      "        [204750],\n",
      "        [185000],\n",
      "        [214000],\n",
      "        [ 94750],\n",
      "        [ 83000],\n",
      "        [128950]])\n",
      "tensor([[205000],\n",
      "        [178000],\n",
      "        [118964],\n",
      "        [198900],\n",
      "        [169500],\n",
      "        [250000],\n",
      "        [100000],\n",
      "        [115000],\n",
      "        [115000],\n",
      "        [190000]])\n",
      "tensor([[136900],\n",
      "        [180000],\n",
      "        [383970],\n",
      "        [217000],\n",
      "        [259500],\n",
      "        [176000],\n",
      "        [139000],\n",
      "        [155000],\n",
      "        [320000],\n",
      "        [163990]])\n",
      "tensor([[180000],\n",
      "        [100000],\n",
      "        [136000],\n",
      "        [153900],\n",
      "        [181000],\n",
      "        [ 84500],\n",
      "        [128000],\n",
      "        [ 87000],\n",
      "        [155000],\n",
      "        [150000]])\n",
      "tensor([[226000],\n",
      "        [244000],\n",
      "        [150750],\n",
      "        [220000],\n",
      "        [180000],\n",
      "        [174000],\n",
      "        [143000],\n",
      "        [171000],\n",
      "        [230000],\n",
      "        [231500]])\n",
      "tensor([[115000],\n",
      "        [260000],\n",
      "        [166000],\n",
      "        [204000],\n",
      "        [125000],\n",
      "        [130000],\n",
      "        [105000],\n",
      "        [222500],\n",
      "        [141000],\n",
      "        [115000]])\n",
      "tensor([[122000],\n",
      "        [372402],\n",
      "        [190000],\n",
      "        [235000],\n",
      "        [125000],\n",
      "        [ 79000],\n",
      "        [109500],\n",
      "        [269500],\n",
      "        [254900],\n",
      "        [320000]])\n",
      "tensor([[162500],\n",
      "        [412500],\n",
      "        [220000],\n",
      "        [103200],\n",
      "        [152000],\n",
      "        [127500],\n",
      "        [190000],\n",
      "        [325624],\n",
      "        [183500],\n",
      "        [228000]])\n",
      "tensor([[128500],\n",
      "        [215000],\n",
      "        [239000],\n",
      "        [163000],\n",
      "        [184000],\n",
      "        [243000],\n",
      "        [211000],\n",
      "        [172500],\n",
      "        [501837],\n",
      "        [100000]])\n",
      "tensor([[177000],\n",
      "        [200100],\n",
      "        [120000],\n",
      "        [200000],\n",
      "        [127000],\n",
      "        [475000],\n",
      "        [173000],\n",
      "        [135000],\n",
      "        [153337],\n",
      "        [286000]])\n",
      "tensor([[315000],\n",
      "        [184000],\n",
      "        [192000],\n",
      "        [130000],\n",
      "        [127000],\n",
      "        [148500],\n",
      "        [311872],\n",
      "        [235000],\n",
      "        [104000],\n",
      "        [274900]])\n",
      "tensor([[140000],\n",
      "        [171500],\n",
      "        [112000],\n",
      "        [149000],\n",
      "        [110000],\n",
      "        [180500],\n",
      "        [143900],\n",
      "        [141000],\n",
      "        [277000],\n",
      "        [145000]])\n",
      "tensor([[ 98000],\n",
      "        [186000],\n",
      "        [252678],\n",
      "        [156000],\n",
      "        [161750],\n",
      "        [134450],\n",
      "        [210000],\n",
      "        [107000],\n",
      "        [311500],\n",
      "        [167240]])\n",
      "tensor([[204900],\n",
      "        [200000],\n",
      "        [179900],\n",
      "        [ 97000],\n",
      "        [386250],\n",
      "        [112000],\n",
      "        [290000],\n",
      "        [106000],\n",
      "        [125000],\n",
      "        [192500]])\n",
      "tensor([[148000],\n",
      "        [403000],\n",
      "        [ 94500],\n",
      "        [128200],\n",
      "        [216500],\n",
      "        [ 89500],\n",
      "        [185500],\n",
      "        [194500],\n",
      "        [318000],\n",
      "        [113000]])\n",
      "tensor([[262500],\n",
      "        [110500],\n",
      "        [ 79000],\n",
      "        [120000],\n",
      "        [205000],\n",
      "        [241500],\n",
      "        [137000],\n",
      "        [140000],\n",
      "        [180000],\n",
      "        [277000]])\n",
      "tensor([[ 76500],\n",
      "        [235000],\n",
      "        [173000],\n",
      "        [158000],\n",
      "        [145000],\n",
      "        [230000],\n",
      "        [207500],\n",
      "        [220000],\n",
      "        [231500],\n",
      "        [ 97000]])\n",
      "tensor([[176000],\n",
      "        [276000],\n",
      "        [151000],\n",
      "        [130000],\n",
      "        [ 73000],\n",
      "        [175500],\n",
      "        [185000],\n",
      "        [179500],\n",
      "        [120500],\n",
      "        [148000]])\n",
      "tensor([[266000],\n",
      "        [241500],\n",
      "        [290000],\n",
      "        [139000],\n",
      "        [124500],\n",
      "        [205000],\n",
      "        [201000],\n",
      "        [141000],\n",
      "        [415298],\n",
      "        [192000]])\n",
      "tensor([[228500],\n",
      "        [185000],\n",
      "        [207500],\n",
      "        [244600],\n",
      "        [179200],\n",
      "        [164700],\n",
      "        [159000],\n",
      "        [ 88000],\n",
      "        [122000],\n",
      "        [153575]])\n",
      "tensor([[233230],\n",
      "        [135900],\n",
      "        [131000],\n",
      "        [235000],\n",
      "        [167000],\n",
      "        [142500],\n",
      "        [152000],\n",
      "        [239000],\n",
      "        [175000],\n",
      "        [158500]])\n",
      "tensor([[157000],\n",
      "        [267000],\n",
      "        [205000],\n",
      "        [149900],\n",
      "        [295000],\n",
      "        [305900],\n",
      "        [225000],\n",
      "        [ 89500],\n",
      "        [ 82500],\n",
      "        [360000]])\n",
      "tensor([[165600],\n",
      "        [132000],\n",
      "        [119900],\n",
      "        [375000],\n",
      "        [178000],\n",
      "        [188500],\n",
      "        [260000],\n",
      "        [270000],\n",
      "        [260000],\n",
      "        [187500]])\n",
      "tensor([[342643],\n",
      "        [354000],\n",
      "        [301000],\n",
      "        [126175],\n",
      "        [242000],\n",
      "        [ 87000],\n",
      "        [324000],\n",
      "        [145250],\n",
      "        [214500],\n",
      "        [ 78000]])\n",
      "tensor([[119000],\n",
      "        [139000],\n",
      "        [284000],\n",
      "        [207000],\n",
      "        [192000],\n",
      "        [228950],\n",
      "        [377426],\n",
      "        [214000],\n",
      "        [202500],\n",
      "        [155000]])\n",
      "tensor([[202900],\n",
      "        [ 82000],\n",
      "        [ 87500],\n",
      "        [266000],\n",
      "        [ 85000],\n",
      "        [140200],\n",
      "        [151500],\n",
      "        [157500],\n",
      "        [154000],\n",
      "        [437154]])\n",
      "tensor([[318061],\n",
      "        [190000],\n",
      "        [ 95000],\n",
      "        [105900],\n",
      "        [140000],\n",
      "        [177500],\n",
      "        [173000],\n",
      "        [134000],\n",
      "        [130000],\n",
      "        [280000]])\n",
      "tensor([[156000],\n",
      "        [145000],\n",
      "        [198500],\n",
      "        [118000],\n",
      "        [190000],\n",
      "        [147000],\n",
      "        [159000],\n",
      "        [165000],\n",
      "        [132000],\n",
      "        [162000]])\n",
      "tensor([[172400],\n",
      "        [134432],\n",
      "        [125000],\n",
      "        [123000],\n",
      "        [219500],\n",
      "        [ 61000],\n",
      "        [148000],\n",
      "        [340000],\n",
      "        [394432],\n",
      "        [179000]])\n",
      "tensor([[127000],\n",
      "        [187750],\n",
      "        [213500],\n",
      "        [ 76000],\n",
      "        [240000],\n",
      "        [192000],\n",
      "        [ 81000],\n",
      "        [125000],\n",
      "        [191000],\n",
      "        [426000]])\n",
      "tensor([[119000],\n",
      "        [215000],\n",
      "        [106500],\n",
      "        [100000],\n",
      "        [109000],\n",
      "        [129000],\n",
      "        [123000],\n",
      "        [169500],\n",
      "        [ 67000],\n",
      "        [241000]])\n",
      "tensor([[245500],\n",
      "        [164990],\n",
      "        [108000],\n",
      "        [258000],\n",
      "        [168000],\n",
      "        [150000],\n",
      "        [115000],\n",
      "        [177000],\n",
      "        [280000],\n",
      "        [339750]])\n",
      "tensor([[ 60000],\n",
      "        [145000],\n",
      "        [222000],\n",
      "        [115000],\n",
      "        [228000],\n",
      "        [181134],\n",
      "        [149500],\n",
      "        [239000],\n",
      "        [126000],\n",
      "        [142000]])\n",
      "tensor([[206300],\n",
      "        [215000],\n",
      "        [113000],\n",
      "        [315000],\n",
      "        [139000],\n",
      "        [135000],\n",
      "        [275000],\n",
      "        [109008],\n",
      "        [195400],\n",
      "        [175000]])\n",
      "tensor([[ 85400],\n",
      "        [ 79900],\n",
      "        [122500],\n",
      "        [181000],\n",
      "        [ 81000],\n",
      "        [212000],\n",
      "        [116000],\n",
      "        [119000],\n",
      "        [ 90350],\n",
      "        [110000]])\n",
      "tensor([[555000],\n",
      "        [118000],\n",
      "        [162900],\n",
      "        [172500],\n",
      "        [210000],\n",
      "        [127500],\n",
      "        [190000],\n",
      "        [199900],\n",
      "        [119500],\n",
      "        [120000]])\n",
      "tensor([[110000],\n",
      "        [280000],\n",
      "        [204000],\n",
      "        [210000],\n",
      "        [188000],\n",
      "        [175500],\n",
      "        [ 98000],\n",
      "        [256000],\n",
      "        [161000],\n",
      "        [110000]])\n",
      "tensor([[263435],\n",
      "        [155000],\n",
      "        [ 62383],\n",
      "        [188700],\n",
      "        [124000],\n",
      "        [178740],\n",
      "        [167000],\n",
      "        [146500],\n",
      "        [250000],\n",
      "        [187000]])\n",
      "tensor([[212000],\n",
      "        [190000],\n",
      "        [148000],\n",
      "        [440000],\n",
      "        [251000],\n",
      "        [132500],\n",
      "        [208900],\n",
      "        [380000],\n",
      "        [297000],\n",
      "        [ 89471]])\n",
      "tensor([[326000],\n",
      "        [374000],\n",
      "        [155000],\n",
      "        [164000],\n",
      "        [132500],\n",
      "        [147000],\n",
      "        [156000],\n",
      "        [175000],\n",
      "        [160000],\n",
      "        [ 86000]])\n",
      "tensor([[115000],\n",
      "        [133000],\n",
      "        [172785],\n",
      "        [155000],\n",
      "        [ 91300],\n",
      "        [ 34900],\n",
      "        [430000],\n",
      "        [184000],\n",
      "        [130000],\n",
      "        [120000]])\n",
      "tensor([[113000],\n",
      "        [226700],\n",
      "        [140000],\n",
      "        [289000],\n",
      "        [147000],\n",
      "        [124500],\n",
      "        [215000],\n",
      "        [208300],\n",
      "        [161000],\n",
      "        [124500]])\n",
      "tensor([[164900],\n",
      "        [202665],\n",
      "        [129900],\n",
      "        [134000],\n",
      "        [ 96500],\n",
      "        [402861],\n",
      "        [158000],\n",
      "        [265000],\n",
      "        [211000],\n",
      "        [234000]])\n",
      "tensor([[106250],\n",
      "        [150000],\n",
      "        [159000],\n",
      "        [184750],\n",
      "        [315750],\n",
      "        [176000],\n",
      "        [132000],\n",
      "        [446261],\n",
      "        [ 86000],\n",
      "        [200624]])\n",
      "tensor([[175000],\n",
      "        [128000],\n",
      "        [107500],\n",
      "        [ 39300],\n",
      "        [178000],\n",
      "        [107500],\n",
      "        [188000],\n",
      "        [111250],\n",
      "        [158000],\n",
      "        [272000]])\n",
      "tensor([[315000],\n",
      "        [248000],\n",
      "        [213250],\n",
      "        [133000],\n",
      "        [179665],\n",
      "        [229000],\n",
      "        [210000],\n",
      "        [129500],\n",
      "        [125000],\n",
      "        [263000]])\n",
      "tensor([[140000],\n",
      "        [112500],\n",
      "        [255500],\n",
      "        [108000],\n",
      "        [284000],\n",
      "        [113000],\n",
      "        [141000],\n",
      "        [108000],\n",
      "        [175000],\n",
      "        [234000]])\n",
      "tensor([[121500],\n",
      "        [170000],\n",
      "        [108000],\n",
      "        [185000],\n",
      "        [268000],\n",
      "        [128000],\n",
      "        [325000],\n",
      "        [214000],\n",
      "        [316600],\n",
      "        [135960]])\n",
      "tensor([[142600],\n",
      "        [120000],\n",
      "        [224500],\n",
      "        [170000],\n",
      "        [139000],\n",
      "        [118500],\n",
      "        [145000],\n",
      "        [164500],\n",
      "        [146000],\n",
      "        [131500]])\n",
      "tensor([[181900],\n",
      "        [253293],\n",
      "        [118500],\n",
      "        [325000],\n",
      "        [133000],\n",
      "        [369900],\n",
      "        [130000],\n",
      "        [137000],\n",
      "        [143000],\n",
      "        [ 79500]])\n",
      "tensor([[185900],\n",
      "        [451950],\n",
      "        [138000],\n",
      "        [140000],\n",
      "        [110000],\n",
      "        [319000],\n",
      "        [114504],\n",
      "        [194201],\n",
      "        [217500],\n",
      "        [151000]])\n",
      "tensor([[275000],\n",
      "        [141000],\n",
      "        [220000],\n",
      "        [151000],\n",
      "        [221000],\n",
      "        [205000],\n",
      "        [152000],\n",
      "        [225000],\n",
      "        [359100],\n",
      "        [118500]])\n",
      "tensor([[313000],\n",
      "        [148000],\n",
      "        [261500],\n",
      "        [147000],\n",
      "        [ 75500],\n",
      "        [137500],\n",
      "        [183200],\n",
      "        [105500],\n",
      "        [314813],\n",
      "        [305000]])\n",
      "tensor([[ 67000],\n",
      "        [240000],\n",
      "        [135000],\n",
      "        [168500],\n",
      "        [165150],\n",
      "        [160000],\n",
      "        [139900],\n",
      "        [153000],\n",
      "        [135000],\n",
      "        [168500]])\n",
      "tensor([[124000],\n",
      "        [209500],\n",
      "        [ 82500],\n",
      "        [139400],\n",
      "        [144000],\n",
      "        [200000],\n",
      "        [ 60000],\n",
      "        [ 93000],\n",
      "        [ 85000],\n",
      "        [264561]])\n",
      "tensor([[274000],\n",
      "        [226000],\n",
      "        [345000],\n",
      "        [152000],\n",
      "        [370878],\n",
      "        [143250],\n",
      "        [ 98300],\n",
      "        [155000],\n",
      "        [155000],\n",
      "        [ 84500]])\n",
      "tensor([[205950],\n",
      "        [108000],\n",
      "        [191000],\n",
      "        [135000],\n",
      "        [350000],\n",
      "        [ 88000],\n",
      "        [145500],\n",
      "        [149000],\n",
      "        [ 97500],\n",
      "        [167000]])\n",
      "tensor([[197900],\n",
      "        [402000],\n",
      "        [110000],\n",
      "        [137500],\n",
      "        [423000],\n",
      "        [230500],\n",
      "        [129000],\n",
      "        [193500],\n",
      "        [168000],\n",
      "        [137500]])\n",
      "tensor([[173500],\n",
      "        [103600],\n",
      "        [165000],\n",
      "        [257500],\n",
      "        [140000],\n",
      "        [148500],\n",
      "        [ 87000],\n",
      "        [109500],\n",
      "        [372500],\n",
      "        [128500]])\n",
      "tensor([[143000],\n",
      "        [159434],\n",
      "        [173000],\n",
      "        [285000],\n",
      "        [221000],\n",
      "        [207500],\n",
      "        [227875],\n",
      "        [148800],\n",
      "        [392000],\n",
      "        [194700]])\n",
      "tensor([[141000],\n",
      "        [755000],\n",
      "        [335000],\n",
      "        [108480],\n",
      "        [141500],\n",
      "        [176000],\n",
      "        [ 89000],\n",
      "        [123500],\n",
      "        [138500],\n",
      "        [196000]])\n",
      "tensor([[312500],\n",
      "        [140000],\n",
      "        [361919],\n",
      "        [140000],\n",
      "        [213000],\n",
      "        [ 55000],\n",
      "        [302000],\n",
      "        [254000],\n",
      "        [179540],\n",
      "        [109900]])\n",
      "tensor([[ 52000],\n",
      "        [102776],\n",
      "        [189000],\n",
      "        [129000],\n",
      "        [130500],\n",
      "        [165000],\n",
      "        [159500],\n",
      "        [157000],\n",
      "        [341000],\n",
      "        [128500]])\n",
      "tensor([[275000],\n",
      "        [143000],\n",
      "        [124500],\n",
      "        [135000],\n",
      "        [320000],\n",
      "        [120500],\n",
      "        [222000],\n",
      "        [194500],\n",
      "        [110000],\n",
      "        [103000]])\n",
      "tensor([[236500],\n",
      "        [187500],\n",
      "        [222500],\n",
      "        [131400],\n",
      "        [108000],\n",
      "        [163000],\n",
      "        [ 93500],\n",
      "        [239900],\n",
      "        [179000],\n",
      "        [190000]])\n",
      "tensor([[132000],\n",
      "        [142000],\n",
      "        [179000],\n",
      "        [175000],\n",
      "        [180000],\n",
      "        [299800],\n",
      "        [236000],\n",
      "        [265979],\n",
      "        [260400],\n",
      "        [ 98000]])\n",
      "tensor([[ 96500],\n",
      "        [162000],\n",
      "        [217000],\n",
      "        [275500],\n",
      "        [156000],\n",
      "        [172500],\n",
      "        [212000],\n",
      "        [158900],\n",
      "        [179400],\n",
      "        [290000]])\n",
      "tensor([[127500],\n",
      "        [100000],\n",
      "        [215200],\n",
      "        [337000],\n",
      "        [270000],\n",
      "        [264132],\n",
      "        [196500],\n",
      "        [160000],\n",
      "        [216837],\n",
      "        [538000]])\n",
      "tensor([[134900],\n",
      "        [102000],\n",
      "        [107000],\n",
      "        [114500],\n",
      "        [395000],\n",
      "        [162000],\n",
      "        [221500],\n",
      "        [142500],\n",
      "        [144000],\n",
      "        [135000]])\n",
      "tensor([[176000],\n",
      "        [175900],\n",
      "        [187100],\n",
      "        [165500],\n",
      "        [128000],\n",
      "        [161500],\n",
      "        [139000],\n",
      "        [233000],\n",
      "        [107900],\n",
      "        [187500]])\n",
      "tensor([[160200],\n",
      "        [146800],\n",
      "        [269790],\n",
      "        [225000],\n",
      "        [194500],\n",
      "        [171000],\n",
      "        [143500],\n",
      "        [110000],\n",
      "        [485000],\n",
      "        [175000]])\n",
      "tensor([[200000],\n",
      "        [109900],\n",
      "        [189000],\n",
      "        [582933],\n",
      "        [118000],\n",
      "        [227680],\n",
      "        [135500],\n",
      "        [223500],\n",
      "        [159950],\n",
      "        [106000]])\n",
      "tensor([[181000],\n",
      "        [144500],\n",
      "        [ 55993],\n",
      "        [157900],\n",
      "        [116000],\n",
      "        [224900],\n",
      "        [137000],\n",
      "        [271000],\n",
      "        [155000],\n",
      "        [224000]])\n",
      "tensor([[183000],\n",
      "        [ 93000],\n",
      "        [225000],\n",
      "        [139500],\n",
      "        [232600],\n",
      "        [385000],\n",
      "        [109500],\n",
      "        [189000],\n",
      "        [185000],\n",
      "        [147400]])\n",
      "tensor([[166000],\n",
      "        [151000],\n",
      "        [237000],\n",
      "        [167000],\n",
      "        [139950],\n",
      "        [128000],\n",
      "        [153500],\n",
      "        [100000],\n",
      "        [144000],\n",
      "        [130500]])\n",
      "tensor([[140000],\n",
      "        [157500],\n",
      "        [174900],\n",
      "        [141000],\n",
      "        [153900],\n",
      "        [171000],\n",
      "        [213000],\n",
      "        [133500],\n",
      "        [240000],\n",
      "        [187000]])\n",
      "tensor([[131500],\n",
      "        [215000],\n",
      "        [164000],\n",
      "        [158000],\n",
      "        [170000],\n",
      "        [127000],\n",
      "        [147000],\n",
      "        [174000],\n",
      "        [152000],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        [250000]])\n",
      "tensor([[189950],\n",
      "        [131500],\n",
      "        [152000],\n",
      "        [132500],\n",
      "        [250580],\n",
      "        [148500],\n",
      "        [248900],\n",
      "        [129000],\n",
      "        [169000],\n",
      "        [236000]])\n",
      "tensor([[109500],\n",
      "        [200500],\n",
      "        [116000],\n",
      "        [133000],\n",
      "        [ 66500],\n",
      "        [303477],\n",
      "        [132250],\n",
      "        [350000],\n",
      "        [148000],\n",
      "        [136500]])\n",
      "tensor([[157000],\n",
      "        [187500],\n",
      "        [178000],\n",
      "        [118500],\n",
      "        [100000],\n",
      "        [328900],\n",
      "        [145000],\n",
      "        [135500],\n",
      "        [268000],\n",
      "        [149500]])\n",
      "tensor([[122900],\n",
      "        [172500],\n",
      "        [154500],\n",
      "        [165000],\n",
      "        [118858],\n",
      "        [140000],\n",
      "        [106500],\n",
      "        [142953],\n",
      "        [611657],\n",
      "        [135000]])\n",
      "tensor([[110000],\n",
      "        [153000],\n",
      "        [180000],\n",
      "        [240000],\n",
      "        [125500],\n",
      "        [128000],\n",
      "        [255000],\n",
      "        [250000],\n",
      "        [131000],\n",
      "        [174000]])\n",
      "tensor([[154300],\n",
      "        [143500],\n",
      "        [ 88000],\n",
      "        [145000],\n",
      "        [173733],\n",
      "        [ 75000],\n",
      "        [ 35311],\n",
      "        [135000],\n",
      "        [238000],\n",
      "        [176500]])\n",
      "tensor([[201000],\n",
      "        [145900],\n",
      "        [169990],\n",
      "        [193000],\n",
      "        [207500],\n",
      "        [175000],\n",
      "        [285000],\n",
      "        [176000],\n",
      "        [236500],\n",
      "        [222000]])\n",
      "tensor([[201000],\n",
      "        [117500],\n",
      "        [320000],\n",
      "        [190000],\n",
      "        [242000],\n",
      "        [ 79900],\n",
      "        [184900],\n",
      "        [253000],\n",
      "        [239799],\n",
      "        [244400]])\n",
      "tensor([[150900],\n",
      "        [214000],\n",
      "        [150000],\n",
      "        [143000],\n",
      "        [137500],\n",
      "        [124900],\n",
      "        [143000],\n",
      "        [270000],\n",
      "        [192500],\n",
      "        [197500]])\n",
      "tensor([[129000],\n",
      "        [119900],\n",
      "        [133900],\n",
      "        [172000],\n",
      "        [127500],\n",
      "        [145000],\n",
      "        [124000],\n",
      "        [132000],\n",
      "        [185000],\n",
      "        [155000]])\n",
      "tensor([[116500],\n",
      "        [272000],\n",
      "        [155000],\n",
      "        [239000],\n",
      "        [214900],\n",
      "        [178900],\n",
      "        [160000],\n",
      "        [135000],\n",
      "        [ 37900],\n",
      "        [140000]])\n",
      "tensor([[135000],\n",
      "        [173000],\n",
      "        [ 99500],\n",
      "        [182000],\n",
      "        [167500],\n",
      "        [165000],\n",
      "        [ 85500],\n",
      "        [199900],\n",
      "        [110000],\n",
      "        [139000]])\n",
      "tensor([[178400],\n",
      "        [336000],\n",
      "        [159895],\n",
      "        [255900],\n",
      "        [126000],\n",
      "        [125000],\n",
      "        [117000],\n",
      "        [395192],\n",
      "        [195000],\n",
      "        [197000]])\n",
      "tensor([[348000],\n",
      "        [168000],\n",
      "        [187000],\n",
      "        [173900],\n",
      "        [337500],\n",
      "        [121600],\n",
      "        [136500],\n",
      "        [185000],\n",
      "        [ 91000],\n",
      "        [206000]])\n",
      "tensor([[ 82000],\n",
      "        [ 86000],\n",
      "        [232000],\n",
      "        [136905],\n",
      "        [181000],\n",
      "        [149900],\n",
      "        [163500],\n",
      "        [ 88000],\n",
      "        [240000],\n",
      "        [102000]])\n",
      "tensor([[135000],\n",
      "        [100000],\n",
      "        [165000],\n",
      "        [ 85000],\n",
      "        [119200],\n",
      "        [227000],\n",
      "        [203000],\n",
      "        [187500],\n",
      "        [160000],\n",
      "        [213490]])\n",
      "tensor([[176000]])\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(data_loader['train']):\n",
    "    print(target)\n",
    "    next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        \n",
    "        # linear layer (330 -> 755001)\n",
    "        self.fc1 = nn.Linear(288, 250)\n",
    "        \n",
    "        # linear layer (500 -> 250)\n",
    "        self.fc2 = nn.Linear(250, 125)\n",
    "        \n",
    "        # linear layer (250 -> 125)\n",
    "        self.fc3 = nn.Linear(125, 75)\n",
    "        \n",
    "        # linear layer (125 -> 1)\n",
    "        self.fc4 = nn.Linear(75, 755001)\n",
    "        \n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.175)\n",
    "        \n",
    "        # LogSoftmax\n",
    "        self.LSM = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h2\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h3\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h4\n",
    "        x = self.fc4(x)\n",
    "        x = self.LSM(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_HR = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_patho.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=288, out_features=250, bias=True)\n",
       "  (fc2): Linear(in_features=250, out_features=125, bias=True)\n",
       "  (fc3): Linear(in_features=125, out_features=75, bias=True)\n",
       "  (fc4): Linear(in_features=75, out_features=755001, bias=True)\n",
       "  (dropout): Dropout(p=0.175, inplace=False)\n",
       "  (LSM): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.SGD(model_HR.parameters(), lr=0.01, momentum = 0.9)\n",
    "\n",
    "VERSION = 'Test_version'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amallet\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 13.529297 \tValidation Loss: 13.499586 \tTime since the beginning 2.7 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (inf --> 13.499586).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 13.456607 \tValidation Loss: 13.371348 \tTime since the beginning 5.5 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (13.499586 --> 13.371348).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 12.068591 \tValidation Loss: 10.759407 \tTime since the beginning 8.2 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (13.371348 --> 10.759407).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 9.589984 \tValidation Loss: 9.756508 \tTime since the beginning 11.1 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (10.759407 --> 9.756508).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 8.349231 \tValidation Loss: 9.516190 \tTime since the beginning 14.0 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.756508 --> 9.516190).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 7.737124 \tValidation Loss: 9.219252 \tTime since the beginning 16.9 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.516190 --> 9.219252).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 7.312042 \tValidation Loss: 9.108428 \tTime since the beginning 19.7 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.219252 --> 9.108428).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 6.913320 \tValidation Loss: 8.981116 \tTime since the beginning 22.5 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.108428 --> 8.981116).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 6.698035 \tValidation Loss: 9.121162 \tTime since the beginning 25.3 min \tLearning rate: 0.010000 \n",
      "Epoch: 10 \tTraining Loss: 6.467889 \tValidation Loss: 8.923680 \tTime since the beginning 28.0 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (8.981116 --> 8.923680).  Saving model ...\n",
      "Epoch: 11 \tTraining Loss: 6.447102 \tValidation Loss: 9.140150 \tTime since the beginning 31.0 min \tLearning rate: 0.010000 \n",
      "Epoch: 12 \tTraining Loss: 6.213996 \tValidation Loss: 9.162203 \tTime since the beginning 34.0 min \tLearning rate: 0.010000 \n",
      "Epoch: 13 \tTraining Loss: 6.089195 \tValidation Loss: 8.919414 \tTime since the beginning 36.9 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (8.923680 --> 8.919414).  Saving model ...\n",
      "Epoch: 14 \tTraining Loss: 5.963094 \tValidation Loss: 9.173710 \tTime since the beginning 39.6 min \tLearning rate: 0.010000 \n",
      "Epoch: 15 \tTraining Loss: 5.869779 \tValidation Loss: 9.358774 \tTime since the beginning 42.4 min \tLearning rate: 0.010000 \n",
      "Epoch: 16 \tTraining Loss: 5.663432 \tValidation Loss: 9.930261 \tTime since the beginning 45.1 min \tLearning rate: 0.010000 \n",
      "Epoch: 17 \tTraining Loss: 5.552683 \tValidation Loss: 9.443781 \tTime since the beginning 47.8 min \tLearning rate: 0.010000 \n",
      "Epoch: 18 \tTraining Loss: 5.351947 \tValidation Loss: 9.708225 \tTime since the beginning 50.7 min \tLearning rate: 0.010000 \n",
      "Epoch: 19 \tTraining Loss: 5.230616 \tValidation Loss: 9.751305 \tTime since the beginning 53.5 min \tLearning rate: 0.010000 \n",
      "Epoch: 20 \tTraining Loss: 5.137531 \tValidation Loss: 9.855995 \tTime since the beginning 56.3 min \tLearning rate: 0.010000 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_res = train(20, data_loader, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 30834240840 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-110-1f411f4803de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_HR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-107-77c27900883e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-104-0bbf1ced8ea9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;31m#h4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLSM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 30834240840 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "model_res = train(20, data_loader2, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter_test = iter(data_loader['test'])\n",
    "print('data_iter\\n',dataiter_test)\n",
    "data_test = dataiter_test.next()\n",
    "data_test_data = data_test[0]\n",
    "print('image test data',data_test_data)\n",
    "\n",
    "model_test = model_HR\n",
    "model_test.load_state_dict(torch.load(VERSION))\n",
    "model_test = model_test.eval()\n",
    "\n",
    "\n",
    "out_fwd = model_test.forward(data_test_data)\n",
    "print('Result preditcion model on dataset:\\n {}\\n'.format(out_fwd))\n",
    "probs = torch.exp(out_fwd)\n",
    "print('probs\\n', probs)\n",
    "print(probs.max())\n",
    "print(probs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
