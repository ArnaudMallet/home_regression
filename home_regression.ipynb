{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "samples_submission_csv = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>...</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1201.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1452.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>1460.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>56.897260</td>\n",
       "      <td>70.049958</td>\n",
       "      <td>10516.828082</td>\n",
       "      <td>6.099315</td>\n",
       "      <td>5.575342</td>\n",
       "      <td>1971.267808</td>\n",
       "      <td>1984.865753</td>\n",
       "      <td>103.685262</td>\n",
       "      <td>443.639726</td>\n",
       "      <td>...</td>\n",
       "      <td>94.244521</td>\n",
       "      <td>46.660274</td>\n",
       "      <td>21.954110</td>\n",
       "      <td>3.409589</td>\n",
       "      <td>15.060959</td>\n",
       "      <td>2.758904</td>\n",
       "      <td>43.489041</td>\n",
       "      <td>6.321918</td>\n",
       "      <td>2007.815753</td>\n",
       "      <td>180921.195890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>421.610009</td>\n",
       "      <td>42.300571</td>\n",
       "      <td>24.284752</td>\n",
       "      <td>9981.264932</td>\n",
       "      <td>1.382997</td>\n",
       "      <td>1.112799</td>\n",
       "      <td>30.202904</td>\n",
       "      <td>20.645407</td>\n",
       "      <td>181.066207</td>\n",
       "      <td>456.098091</td>\n",
       "      <td>...</td>\n",
       "      <td>125.338794</td>\n",
       "      <td>66.256028</td>\n",
       "      <td>61.119149</td>\n",
       "      <td>29.317331</td>\n",
       "      <td>55.757415</td>\n",
       "      <td>40.177307</td>\n",
       "      <td>496.123024</td>\n",
       "      <td>2.703626</td>\n",
       "      <td>1.328095</td>\n",
       "      <td>79442.502883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "      <td>34900.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>365.750000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7553.500000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1954.000000</td>\n",
       "      <td>1967.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "      <td>129975.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>730.500000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>69.000000</td>\n",
       "      <td>9478.500000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>383.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>163000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>1095.250000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11601.500000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>712.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "      <td>214000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1460.000000</td>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>857.000000</td>\n",
       "      <td>547.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>738.000000</td>\n",
       "      <td>15500.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>755000.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Id   MSSubClass  LotFrontage        LotArea  OverallQual  \\\n",
       "count  1460.000000  1460.000000  1201.000000    1460.000000  1460.000000   \n",
       "mean    730.500000    56.897260    70.049958   10516.828082     6.099315   \n",
       "std     421.610009    42.300571    24.284752    9981.264932     1.382997   \n",
       "min       1.000000    20.000000    21.000000    1300.000000     1.000000   \n",
       "25%     365.750000    20.000000    59.000000    7553.500000     5.000000   \n",
       "50%     730.500000    50.000000    69.000000    9478.500000     6.000000   \n",
       "75%    1095.250000    70.000000    80.000000   11601.500000     7.000000   \n",
       "max    1460.000000   190.000000   313.000000  215245.000000    10.000000   \n",
       "\n",
       "       OverallCond    YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1  ...  \\\n",
       "count  1460.000000  1460.000000   1460.000000  1452.000000  1460.000000  ...   \n",
       "mean      5.575342  1971.267808   1984.865753   103.685262   443.639726  ...   \n",
       "std       1.112799    30.202904     20.645407   181.066207   456.098091  ...   \n",
       "min       1.000000  1872.000000   1950.000000     0.000000     0.000000  ...   \n",
       "25%       5.000000  1954.000000   1967.000000     0.000000     0.000000  ...   \n",
       "50%       5.000000  1973.000000   1994.000000     0.000000   383.500000  ...   \n",
       "75%       6.000000  2000.000000   2004.000000   166.000000   712.250000  ...   \n",
       "max       9.000000  2010.000000   2010.000000  1600.000000  5644.000000  ...   \n",
       "\n",
       "        WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  ScreenPorch  \\\n",
       "count  1460.000000  1460.000000    1460.000000  1460.000000  1460.000000   \n",
       "mean     94.244521    46.660274      21.954110     3.409589    15.060959   \n",
       "std     125.338794    66.256028      61.119149    29.317331    55.757415   \n",
       "min       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000       0.000000     0.000000     0.000000   \n",
       "50%       0.000000    25.000000       0.000000     0.000000     0.000000   \n",
       "75%     168.000000    68.000000       0.000000     0.000000     0.000000   \n",
       "max     857.000000   547.000000     552.000000   508.000000   480.000000   \n",
       "\n",
       "          PoolArea       MiscVal       MoSold       YrSold      SalePrice  \n",
       "count  1460.000000   1460.000000  1460.000000  1460.000000    1460.000000  \n",
       "mean      2.758904     43.489041     6.321918  2007.815753  180921.195890  \n",
       "std      40.177307    496.123024     2.703626     1.328095   79442.502883  \n",
       "min       0.000000      0.000000     1.000000  2006.000000   34900.000000  \n",
       "25%       0.000000      0.000000     5.000000  2007.000000  129975.000000  \n",
       "50%       0.000000      0.000000     6.000000  2008.000000  163000.000000  \n",
       "75%       0.000000      0.000000     8.000000  2009.000000  214000.000000  \n",
       "max     738.000000  15500.000000    12.000000  2010.000000  755000.000000  \n",
       "\n",
       "[8 rows x 38 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Id                  0\n",
       "MSSubClass          0\n",
       "MSZoning            0\n",
       "LotFrontage       259\n",
       "LotArea             0\n",
       "Street              0\n",
       "Alley            1369\n",
       "LotShape            0\n",
       "LandContour         0\n",
       "Utilities           0\n",
       "LotConfig           0\n",
       "LandSlope           0\n",
       "Neighborhood        0\n",
       "Condition1          0\n",
       "Condition2          0\n",
       "BldgType            0\n",
       "HouseStyle          0\n",
       "OverallQual         0\n",
       "OverallCond         0\n",
       "YearBuilt           0\n",
       "YearRemodAdd        0\n",
       "RoofStyle           0\n",
       "RoofMatl            0\n",
       "Exterior1st         0\n",
       "Exterior2nd         0\n",
       "MasVnrType          8\n",
       "MasVnrArea          8\n",
       "ExterQual           0\n",
       "ExterCond           0\n",
       "Foundation          0\n",
       "BsmtQual           37\n",
       "BsmtCond           37\n",
       "BsmtExposure       38\n",
       "BsmtFinType1       37\n",
       "BsmtFinSF1          0\n",
       "BsmtFinType2       38\n",
       "BsmtFinSF2          0\n",
       "BsmtUnfSF           0\n",
       "TotalBsmtSF         0\n",
       "Heating             0\n",
       "HeatingQC           0\n",
       "CentralAir          0\n",
       "Electrical          1\n",
       "1stFlrSF            0\n",
       "2ndFlrSF            0\n",
       "LowQualFinSF        0\n",
       "GrLivArea           0\n",
       "BsmtFullBath        0\n",
       "BsmtHalfBath        0\n",
       "FullBath            0\n",
       "HalfBath            0\n",
       "BedroomAbvGr        0\n",
       "KitchenAbvGr        0\n",
       "KitchenQual         0\n",
       "TotRmsAbvGrd        0\n",
       "Functional          0\n",
       "Fireplaces          0\n",
       "FireplaceQu       690\n",
       "GarageType         81\n",
       "GarageYrBlt        81\n",
       "GarageFinish       81\n",
       "GarageCars          0\n",
       "GarageArea          0\n",
       "GarageQual         81\n",
       "GarageCond         81\n",
       "PavedDrive          0\n",
       "WoodDeckSF          0\n",
       "OpenPorchSF         0\n",
       "EnclosedPorch       0\n",
       "3SsnPorch           0\n",
       "ScreenPorch         0\n",
       "PoolArea            0\n",
       "PoolQC           1453\n",
       "Fence            1179\n",
       "MiscFeature      1406\n",
       "MiscVal             0\n",
       "MoSold              0\n",
       "YrSold              0\n",
       "SaleType            0\n",
       "SaleCondition       0\n",
       "SalePrice           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_csv.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_valid_data(data, perc=0.7):\n",
    "    return data.head(int(len(data)*(perc)))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id             1460\n",
      "SalePrice    755000\n",
      "dtype: int64\n",
      "before\n",
      "(1021, 289)\n",
      "(439, 289)\n",
      "(1021, 2)\n",
      "(439, 2)\n",
      "(1459, 289)\n",
      "(1459, 1)\n",
      "after\n",
      "(1021, 288)\n",
      "(439, 288)\n",
      "(1021, 1)\n",
      "(439, 1)\n",
      "(1459, 288)\n",
      "(1459, 1)\n"
     ]
    }
   ],
   "source": [
    "train_wo_SP = train_csv.drop(['SalePrice'], axis='columns')\n",
    "#print(train_wo_SP)\n",
    "# concat train and test features to have the same number of columns one the dummies features appear\n",
    "all_features = pd.concat([train_wo_SP, test_csv], keys=[\"train\", \"test\"])\n",
    "#print(all_features)\n",
    "# Normalize the numerical features\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "# creathe the dummies for train and test set\n",
    "all_features_dummies = pd.get_dummies(all_features)\n",
    "#print(all_features_dummies)\n",
    "\n",
    "# creation of the label of train dataset\n",
    "train_label1 = train_csv['Id']\n",
    "train_label2 = train_csv['SalePrice']\n",
    "train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "train_label['Id'] = train_label1\n",
    "train_label['SalePrice'] = train_label2\n",
    "print(train_label.max())\n",
    "\n",
    "#Split Data - creation of the Validation dataset\n",
    "train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "\n",
    "#Split label - creation of the validation labelset\n",
    "label_train = split_train_valid_data(train_label)\n",
    "label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "\n",
    "# creation of the test data set\n",
    "test_data = all_features_dummies.loc['test']\n",
    "\n",
    "# creation of an Empty label test\n",
    "label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "\n",
    "print('before')\n",
    "\n",
    "train_data = train_data.astype(np.float32)\n",
    "valid_data = valid_data.astype(np.float32)\n",
    "test_data = test_data.astype(np.float32)\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(label_train.shape)\n",
    "print(label_valid.shape)\n",
    "print(test_data.shape)\n",
    "print(label_test.shape)\n",
    "\n",
    "# remove 'ID' columns - data\n",
    "train_data = train_data.drop(['Id'], axis=1)\n",
    "train_data = train_data.fillna(0)\n",
    "valid_data = valid_data.drop(['Id'],axis=1)\n",
    "valid_data = valid_data.fillna(0)\n",
    "test_data = test_data.drop(['Id'], axis=1)\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "# remove 'ID' column - label\n",
    "label_train = label_train.drop(['Id'], axis=1)\n",
    "label_valid = label_valid.drop(['Id'], axis=1)\n",
    "\n",
    "print('after')\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(label_train.shape)\n",
    "print(label_valid.shape)\n",
    "print(test_data.shape)\n",
    "print(label_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "class PrepareData(Dataset):\n",
    "\n",
    "    def __init__(self, In, Out):\n",
    "        if not torch.is_tensor(In):\n",
    "            In = In.to_numpy()\n",
    "            self.In = torch.from_numpy(In)\n",
    "        if not torch.is_tensor(Out):\n",
    "            Out = Out.to_numpy()\n",
    "            self.Out = torch.from_numpy(Out)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.In)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.In[idx], self.Out[idx]\n",
    "        \n",
    "\n",
    "\n",
    "data_dataset = {x: PrepareData(In=train_data if x == 'train'\n",
    "                               else valid_data if x =='valid'\n",
    "                               else test_data, \n",
    "                               Out=label_train if x == 'train'\n",
    "                               else label_valid if x == 'valid'\n",
    "                               else label_test)\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader = {x: torch.utils.data.DataLoader(data_dataset[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([288])\n",
      "\n",
      "Target at the first row:  tensor([208500])\n",
      "Target format at the first row: tensor([208500])\n",
      "Target format at the first row: torch.Size([1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "img, lab_target = data_dataset['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file_data, csv_file_test, id_col, target_col, data='train'):\n",
    "        self.data_train= pd.read_csv(csv_file_data)\n",
    "        self.data_test = pd.read_csv(csv_file_test)\n",
    "        self.id        = id_col\n",
    "        self.target    = target_col\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data == 'train':\n",
    "            return len(self.data_train)\n",
    "        else:\n",
    "            return len(self.data_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # remove the target column\n",
    "        train_wo_SP = self.data_train.drop(self.target, axis='columns')\n",
    "        # concat train and test features to have the same number of columns one the dummies features appear\n",
    "        all_features = pd.concat([train_wo_SP, self.data_test], keys=[\"train\", \"test\"])\n",
    "        # Normalize the numerical features\n",
    "        numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "        all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "        # creathe the dummies for train and test set\n",
    "        all_features_dummies = pd.get_dummies(all_features)\n",
    "        \n",
    "        # creation of the label of train dataset\n",
    "        train_label1 = train_csv['Id']\n",
    "        train_label2 = train_csv['SalePrice']\n",
    "        train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "        train_label['Id'] = train_label1\n",
    "        train_label['SalePrice'] = train_label2\n",
    "\n",
    "        #Split Data - creation of the Validation dataset\n",
    "        train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "        valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "        #Split label - creation of the validation labelset\n",
    "        label_train = split_train_valid_data(train_label)\n",
    "        label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "         \n",
    "        # creation of the test data set\n",
    "        test_data = all_features_dummies.loc['test']\n",
    "        \n",
    "        # creation of an Empty label test\n",
    "        label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "        \n",
    "        train_data = train_data.astype(np.float32)\n",
    "        valid_data = valid_data.astype(np.float32)\n",
    "        test_data = test_data.astype(np.float32)\n",
    "        \n",
    "        # remove 'ID' columns - data\n",
    "        train_data = train_data.drop(['Id'], axis=1)\n",
    "        valid_data = valid_data.drop(['Id'],axis=1)\n",
    "        test_data = test_data.drop(['Id'], axis=1)\n",
    "        \n",
    "        # remove 'ID' column - label\n",
    "        label_train = label_train.drop(['Id'], axis=1)\n",
    "        label_valid = label_valid.drop(['Id'], axis=1)\n",
    "            \n",
    "        # data preparation\n",
    "        if self.data == 'train':\n",
    "            use_data = train_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'valid':\n",
    "            use_data = valid_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'test':\n",
    "            use_data = test_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "            \n",
    "        # label preparation\n",
    "        if self.data == 'train':\n",
    "            label_data = label_train.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'valid':\n",
    "            label_data = label_valid.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'test':\n",
    "            label_data = label_test.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        \n",
    "        return use_data, label_data\n",
    "\n",
    "params = {\n",
    "    'id_col':'Id',  \n",
    "    'target_col': ['SalePrice'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataset2 = {x: CustomDataset(csv_file_data=\"train.csv\" , \n",
    "                                   csv_file_test=\"test.csv\", \n",
    "                                   **params, \n",
    "                                   data='train' if x == 'train'\n",
    "                                   else 'valid' if x =='valid'\n",
    "                                   else 'test')\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader2 = {x: torch.utils.data.DataLoader(data_dataset2[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([1021, 288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([1021, 288])\n",
      "\n",
      "Target at the first row:  tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: torch.Size([1021, 1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 1021, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1021, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "img, lab_target = data_dataset2['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader2['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        [140000],\n",
      "        [250000],\n",
      "        [143000],\n",
      "        [307000],\n",
      "        [200000],\n",
      "        [129900],\n",
      "        [118000]])\n",
      "tensor([[129500],\n",
      "        [345000],\n",
      "        [144000],\n",
      "        [279500],\n",
      "        [157000],\n",
      "        [132000],\n",
      "        [149000],\n",
      "        [ 90000],\n",
      "        [159000],\n",
      "        [139000]])\n",
      "tensor([[325300],\n",
      "        [139400],\n",
      "        [230000],\n",
      "        [129900],\n",
      "        [154000],\n",
      "        [256300],\n",
      "        [134800],\n",
      "        [306000],\n",
      "        [207500],\n",
      "        [ 68500]])\n",
      "tensor([[ 40000],\n",
      "        [149350],\n",
      "        [179900],\n",
      "        [165500],\n",
      "        [277500],\n",
      "        [309000],\n",
      "        [145000],\n",
      "        [153000],\n",
      "        [109000],\n",
      "        [ 82000]])\n",
      "tensor([[160000],\n",
      "        [170000],\n",
      "        [144000],\n",
      "        [130250],\n",
      "        [141000],\n",
      "        [319900],\n",
      "        [239686],\n",
      "        [249700],\n",
      "        [113000],\n",
      "        [127000]])\n",
      "tensor([[177000],\n",
      "        [114500],\n",
      "        [110000],\n",
      "        [385000],\n",
      "        [130000],\n",
      "        [180500],\n",
      "        [172500],\n",
      "        [196500],\n",
      "        [438780],\n",
      "        [124900]])\n",
      "tensor([[158000],\n",
      "        [101000],\n",
      "        [202500],\n",
      "        [140000],\n",
      "        [219500],\n",
      "        [317000],\n",
      "        [180000],\n",
      "        [226000],\n",
      "        [ 80000],\n",
      "        [225000]])\n",
      "tensor([[244000],\n",
      "        [129500],\n",
      "        [185000],\n",
      "        [144900],\n",
      "        [107400],\n",
      "        [ 91000],\n",
      "        [135750],\n",
      "        [127000],\n",
      "        [136500],\n",
      "        [110000]])\n",
      "tensor([[193500],\n",
      "        [153500],\n",
      "        [245000],\n",
      "        [126500],\n",
      "        [168500],\n",
      "        [260000],\n",
      "        [174000],\n",
      "        [164500],\n",
      "        [ 85000],\n",
      "        [123600]])\n",
      "tensor([[109900],\n",
      "        [ 98600],\n",
      "        [163500],\n",
      "        [133900],\n",
      "        [204750],\n",
      "        [185000],\n",
      "        [214000],\n",
      "        [ 94750],\n",
      "        [ 83000],\n",
      "        [128950]])\n",
      "tensor([[205000],\n",
      "        [178000],\n",
      "        [118964],\n",
      "        [198900],\n",
      "        [169500],\n",
      "        [250000],\n",
      "        [100000],\n",
      "        [115000],\n",
      "        [115000],\n",
      "        [190000]])\n",
      "tensor([[136900],\n",
      "        [180000],\n",
      "        [383970],\n",
      "        [217000],\n",
      "        [259500],\n",
      "        [176000],\n",
      "        [139000],\n",
      "        [155000],\n",
      "        [320000],\n",
      "        [163990]])\n",
      "tensor([[180000],\n",
      "        [100000],\n",
      "        [136000],\n",
      "        [153900],\n",
      "        [181000],\n",
      "        [ 84500],\n",
      "        [128000],\n",
      "        [ 87000],\n",
      "        [155000],\n",
      "        [150000]])\n",
      "tensor([[226000],\n",
      "        [244000],\n",
      "        [150750],\n",
      "        [220000],\n",
      "        [180000],\n",
      "        [174000],\n",
      "        [143000],\n",
      "        [171000],\n",
      "        [230000],\n",
      "        [231500]])\n",
      "tensor([[115000],\n",
      "        [260000],\n",
      "        [166000],\n",
      "        [204000],\n",
      "        [125000],\n",
      "        [130000],\n",
      "        [105000],\n",
      "        [222500],\n",
      "        [141000],\n",
      "        [115000]])\n",
      "tensor([[122000],\n",
      "        [372402],\n",
      "        [190000],\n",
      "        [235000],\n",
      "        [125000],\n",
      "        [ 79000],\n",
      "        [109500],\n",
      "        [269500],\n",
      "        [254900],\n",
      "        [320000]])\n",
      "tensor([[162500],\n",
      "        [412500],\n",
      "        [220000],\n",
      "        [103200],\n",
      "        [152000],\n",
      "        [127500],\n",
      "        [190000],\n",
      "        [325624],\n",
      "        [183500],\n",
      "        [228000]])\n",
      "tensor([[128500],\n",
      "        [215000],\n",
      "        [239000],\n",
      "        [163000],\n",
      "        [184000],\n",
      "        [243000],\n",
      "        [211000],\n",
      "        [172500],\n",
      "        [501837],\n",
      "        [100000]])\n",
      "tensor([[177000],\n",
      "        [200100],\n",
      "        [120000],\n",
      "        [200000],\n",
      "        [127000],\n",
      "        [475000],\n",
      "        [173000],\n",
      "        [135000],\n",
      "        [153337],\n",
      "        [286000]])\n",
      "tensor([[315000],\n",
      "        [184000],\n",
      "        [192000],\n",
      "        [130000],\n",
      "        [127000],\n",
      "        [148500],\n",
      "        [311872],\n",
      "        [235000],\n",
      "        [104000],\n",
      "        [274900]])\n",
      "tensor([[140000],\n",
      "        [171500],\n",
      "        [112000],\n",
      "        [149000],\n",
      "        [110000],\n",
      "        [180500],\n",
      "        [143900],\n",
      "        [141000],\n",
      "        [277000],\n",
      "        [145000]])\n",
      "tensor([[ 98000],\n",
      "        [186000],\n",
      "        [252678],\n",
      "        [156000],\n",
      "        [161750],\n",
      "        [134450],\n",
      "        [210000],\n",
      "        [107000],\n",
      "        [311500],\n",
      "        [167240]])\n",
      "tensor([[204900],\n",
      "        [200000],\n",
      "        [179900],\n",
      "        [ 97000],\n",
      "        [386250],\n",
      "        [112000],\n",
      "        [290000],\n",
      "        [106000],\n",
      "        [125000],\n",
      "        [192500]])\n",
      "tensor([[148000],\n",
      "        [403000],\n",
      "        [ 94500],\n",
      "        [128200],\n",
      "        [216500],\n",
      "        [ 89500],\n",
      "        [185500],\n",
      "        [194500],\n",
      "        [318000],\n",
      "        [113000]])\n",
      "tensor([[262500],\n",
      "        [110500],\n",
      "        [ 79000],\n",
      "        [120000],\n",
      "        [205000],\n",
      "        [241500],\n",
      "        [137000],\n",
      "        [140000],\n",
      "        [180000],\n",
      "        [277000]])\n",
      "tensor([[ 76500],\n",
      "        [235000],\n",
      "        [173000],\n",
      "        [158000],\n",
      "        [145000],\n",
      "        [230000],\n",
      "        [207500],\n",
      "        [220000],\n",
      "        [231500],\n",
      "        [ 97000]])\n",
      "tensor([[176000],\n",
      "        [276000],\n",
      "        [151000],\n",
      "        [130000],\n",
      "        [ 73000],\n",
      "        [175500],\n",
      "        [185000],\n",
      "        [179500],\n",
      "        [120500],\n",
      "        [148000]])\n",
      "tensor([[266000],\n",
      "        [241500],\n",
      "        [290000],\n",
      "        [139000],\n",
      "        [124500],\n",
      "        [205000],\n",
      "        [201000],\n",
      "        [141000],\n",
      "        [415298],\n",
      "        [192000]])\n",
      "tensor([[228500],\n",
      "        [185000],\n",
      "        [207500],\n",
      "        [244600],\n",
      "        [179200],\n",
      "        [164700],\n",
      "        [159000],\n",
      "        [ 88000],\n",
      "        [122000],\n",
      "        [153575]])\n",
      "tensor([[233230],\n",
      "        [135900],\n",
      "        [131000],\n",
      "        [235000],\n",
      "        [167000],\n",
      "        [142500],\n",
      "        [152000],\n",
      "        [239000],\n",
      "        [175000],\n",
      "        [158500]])\n",
      "tensor([[157000],\n",
      "        [267000],\n",
      "        [205000],\n",
      "        [149900],\n",
      "        [295000],\n",
      "        [305900],\n",
      "        [225000],\n",
      "        [ 89500],\n",
      "        [ 82500],\n",
      "        [360000]])\n",
      "tensor([[165600],\n",
      "        [132000],\n",
      "        [119900],\n",
      "        [375000],\n",
      "        [178000],\n",
      "        [188500],\n",
      "        [260000],\n",
      "        [270000],\n",
      "        [260000],\n",
      "        [187500]])\n",
      "tensor([[342643],\n",
      "        [354000],\n",
      "        [301000],\n",
      "        [126175],\n",
      "        [242000],\n",
      "        [ 87000],\n",
      "        [324000],\n",
      "        [145250],\n",
      "        [214500],\n",
      "        [ 78000]])\n",
      "tensor([[119000],\n",
      "        [139000],\n",
      "        [284000],\n",
      "        [207000],\n",
      "        [192000],\n",
      "        [228950],\n",
      "        [377426],\n",
      "        [214000],\n",
      "        [202500],\n",
      "        [155000]])\n",
      "tensor([[202900],\n",
      "        [ 82000],\n",
      "        [ 87500],\n",
      "        [266000],\n",
      "        [ 85000],\n",
      "        [140200],\n",
      "        [151500],\n",
      "        [157500],\n",
      "        [154000],\n",
      "        [437154]])\n",
      "tensor([[318061],\n",
      "        [190000],\n",
      "        [ 95000],\n",
      "        [105900],\n",
      "        [140000],\n",
      "        [177500],\n",
      "        [173000],\n",
      "        [134000],\n",
      "        [130000],\n",
      "        [280000]])\n",
      "tensor([[156000],\n",
      "        [145000],\n",
      "        [198500],\n",
      "        [118000],\n",
      "        [190000],\n",
      "        [147000],\n",
      "        [159000],\n",
      "        [165000],\n",
      "        [132000],\n",
      "        [162000]])\n",
      "tensor([[172400],\n",
      "        [134432],\n",
      "        [125000],\n",
      "        [123000],\n",
      "        [219500],\n",
      "        [ 61000],\n",
      "        [148000],\n",
      "        [340000],\n",
      "        [394432],\n",
      "        [179000]])\n",
      "tensor([[127000],\n",
      "        [187750],\n",
      "        [213500],\n",
      "        [ 76000],\n",
      "        [240000],\n",
      "        [192000],\n",
      "        [ 81000],\n",
      "        [125000],\n",
      "        [191000],\n",
      "        [426000]])\n",
      "tensor([[119000],\n",
      "        [215000],\n",
      "        [106500],\n",
      "        [100000],\n",
      "        [109000],\n",
      "        [129000],\n",
      "        [123000],\n",
      "        [169500],\n",
      "        [ 67000],\n",
      "        [241000]])\n",
      "tensor([[245500],\n",
      "        [164990],\n",
      "        [108000],\n",
      "        [258000],\n",
      "        [168000],\n",
      "        [150000],\n",
      "        [115000],\n",
      "        [177000],\n",
      "        [280000],\n",
      "        [339750]])\n",
      "tensor([[ 60000],\n",
      "        [145000],\n",
      "        [222000],\n",
      "        [115000],\n",
      "        [228000],\n",
      "        [181134],\n",
      "        [149500],\n",
      "        [239000],\n",
      "        [126000],\n",
      "        [142000]])\n",
      "tensor([[206300],\n",
      "        [215000],\n",
      "        [113000],\n",
      "        [315000],\n",
      "        [139000],\n",
      "        [135000],\n",
      "        [275000],\n",
      "        [109008],\n",
      "        [195400],\n",
      "        [175000]])\n",
      "tensor([[ 85400],\n",
      "        [ 79900],\n",
      "        [122500],\n",
      "        [181000],\n",
      "        [ 81000],\n",
      "        [212000],\n",
      "        [116000],\n",
      "        [119000],\n",
      "        [ 90350],\n",
      "        [110000]])\n",
      "tensor([[555000],\n",
      "        [118000],\n",
      "        [162900],\n",
      "        [172500],\n",
      "        [210000],\n",
      "        [127500],\n",
      "        [190000],\n",
      "        [199900],\n",
      "        [119500],\n",
      "        [120000]])\n",
      "tensor([[110000],\n",
      "        [280000],\n",
      "        [204000],\n",
      "        [210000],\n",
      "        [188000],\n",
      "        [175500],\n",
      "        [ 98000],\n",
      "        [256000],\n",
      "        [161000],\n",
      "        [110000]])\n",
      "tensor([[263435],\n",
      "        [155000],\n",
      "        [ 62383],\n",
      "        [188700],\n",
      "        [124000],\n",
      "        [178740],\n",
      "        [167000],\n",
      "        [146500],\n",
      "        [250000],\n",
      "        [187000]])\n",
      "tensor([[212000],\n",
      "        [190000],\n",
      "        [148000],\n",
      "        [440000],\n",
      "        [251000],\n",
      "        [132500],\n",
      "        [208900],\n",
      "        [380000],\n",
      "        [297000],\n",
      "        [ 89471]])\n",
      "tensor([[326000],\n",
      "        [374000],\n",
      "        [155000],\n",
      "        [164000],\n",
      "        [132500],\n",
      "        [147000],\n",
      "        [156000],\n",
      "        [175000],\n",
      "        [160000],\n",
      "        [ 86000]])\n",
      "tensor([[115000],\n",
      "        [133000],\n",
      "        [172785],\n",
      "        [155000],\n",
      "        [ 91300],\n",
      "        [ 34900],\n",
      "        [430000],\n",
      "        [184000],\n",
      "        [130000],\n",
      "        [120000]])\n",
      "tensor([[113000],\n",
      "        [226700],\n",
      "        [140000],\n",
      "        [289000],\n",
      "        [147000],\n",
      "        [124500],\n",
      "        [215000],\n",
      "        [208300],\n",
      "        [161000],\n",
      "        [124500]])\n",
      "tensor([[164900],\n",
      "        [202665],\n",
      "        [129900],\n",
      "        [134000],\n",
      "        [ 96500],\n",
      "        [402861],\n",
      "        [158000],\n",
      "        [265000],\n",
      "        [211000],\n",
      "        [234000]])\n",
      "tensor([[106250],\n",
      "        [150000],\n",
      "        [159000],\n",
      "        [184750],\n",
      "        [315750],\n",
      "        [176000],\n",
      "        [132000],\n",
      "        [446261],\n",
      "        [ 86000],\n",
      "        [200624]])\n",
      "tensor([[175000],\n",
      "        [128000],\n",
      "        [107500],\n",
      "        [ 39300],\n",
      "        [178000],\n",
      "        [107500],\n",
      "        [188000],\n",
      "        [111250],\n",
      "        [158000],\n",
      "        [272000]])\n",
      "tensor([[315000],\n",
      "        [248000],\n",
      "        [213250],\n",
      "        [133000],\n",
      "        [179665],\n",
      "        [229000],\n",
      "        [210000],\n",
      "        [129500],\n",
      "        [125000],\n",
      "        [263000]])\n",
      "tensor([[140000],\n",
      "        [112500],\n",
      "        [255500],\n",
      "        [108000],\n",
      "        [284000],\n",
      "        [113000],\n",
      "        [141000],\n",
      "        [108000],\n",
      "        [175000],\n",
      "        [234000]])\n",
      "tensor([[121500],\n",
      "        [170000],\n",
      "        [108000],\n",
      "        [185000],\n",
      "        [268000],\n",
      "        [128000],\n",
      "        [325000],\n",
      "        [214000],\n",
      "        [316600],\n",
      "        [135960]])\n",
      "tensor([[142600],\n",
      "        [120000],\n",
      "        [224500],\n",
      "        [170000],\n",
      "        [139000],\n",
      "        [118500],\n",
      "        [145000],\n",
      "        [164500],\n",
      "        [146000],\n",
      "        [131500]])\n",
      "tensor([[181900],\n",
      "        [253293],\n",
      "        [118500],\n",
      "        [325000],\n",
      "        [133000],\n",
      "        [369900],\n",
      "        [130000],\n",
      "        [137000],\n",
      "        [143000],\n",
      "        [ 79500]])\n",
      "tensor([[185900],\n",
      "        [451950],\n",
      "        [138000],\n",
      "        [140000],\n",
      "        [110000],\n",
      "        [319000],\n",
      "        [114504],\n",
      "        [194201],\n",
      "        [217500],\n",
      "        [151000]])\n",
      "tensor([[275000],\n",
      "        [141000],\n",
      "        [220000],\n",
      "        [151000],\n",
      "        [221000],\n",
      "        [205000],\n",
      "        [152000],\n",
      "        [225000],\n",
      "        [359100],\n",
      "        [118500]])\n",
      "tensor([[313000],\n",
      "        [148000],\n",
      "        [261500],\n",
      "        [147000],\n",
      "        [ 75500],\n",
      "        [137500],\n",
      "        [183200],\n",
      "        [105500],\n",
      "        [314813],\n",
      "        [305000]])\n",
      "tensor([[ 67000],\n",
      "        [240000],\n",
      "        [135000],\n",
      "        [168500],\n",
      "        [165150],\n",
      "        [160000],\n",
      "        [139900],\n",
      "        [153000],\n",
      "        [135000],\n",
      "        [168500]])\n",
      "tensor([[124000],\n",
      "        [209500],\n",
      "        [ 82500],\n",
      "        [139400],\n",
      "        [144000],\n",
      "        [200000],\n",
      "        [ 60000],\n",
      "        [ 93000],\n",
      "        [ 85000],\n",
      "        [264561]])\n",
      "tensor([[274000],\n",
      "        [226000],\n",
      "        [345000],\n",
      "        [152000],\n",
      "        [370878],\n",
      "        [143250],\n",
      "        [ 98300],\n",
      "        [155000],\n",
      "        [155000],\n",
      "        [ 84500]])\n",
      "tensor([[205950],\n",
      "        [108000],\n",
      "        [191000],\n",
      "        [135000],\n",
      "        [350000],\n",
      "        [ 88000],\n",
      "        [145500],\n",
      "        [149000],\n",
      "        [ 97500],\n",
      "        [167000]])\n",
      "tensor([[197900],\n",
      "        [402000],\n",
      "        [110000],\n",
      "        [137500],\n",
      "        [423000],\n",
      "        [230500],\n",
      "        [129000],\n",
      "        [193500],\n",
      "        [168000],\n",
      "        [137500]])\n",
      "tensor([[173500],\n",
      "        [103600],\n",
      "        [165000],\n",
      "        [257500],\n",
      "        [140000],\n",
      "        [148500],\n",
      "        [ 87000],\n",
      "        [109500],\n",
      "        [372500],\n",
      "        [128500]])\n",
      "tensor([[143000],\n",
      "        [159434],\n",
      "        [173000],\n",
      "        [285000],\n",
      "        [221000],\n",
      "        [207500],\n",
      "        [227875],\n",
      "        [148800],\n",
      "        [392000],\n",
      "        [194700]])\n",
      "tensor([[141000],\n",
      "        [755000],\n",
      "        [335000],\n",
      "        [108480],\n",
      "        [141500],\n",
      "        [176000],\n",
      "        [ 89000],\n",
      "        [123500],\n",
      "        [138500],\n",
      "        [196000]])\n",
      "tensor([[312500],\n",
      "        [140000],\n",
      "        [361919],\n",
      "        [140000],\n",
      "        [213000],\n",
      "        [ 55000],\n",
      "        [302000],\n",
      "        [254000],\n",
      "        [179540],\n",
      "        [109900]])\n",
      "tensor([[ 52000],\n",
      "        [102776],\n",
      "        [189000],\n",
      "        [129000],\n",
      "        [130500],\n",
      "        [165000],\n",
      "        [159500],\n",
      "        [157000],\n",
      "        [341000],\n",
      "        [128500]])\n",
      "tensor([[275000],\n",
      "        [143000],\n",
      "        [124500],\n",
      "        [135000],\n",
      "        [320000],\n",
      "        [120500],\n",
      "        [222000],\n",
      "        [194500],\n",
      "        [110000],\n",
      "        [103000]])\n",
      "tensor([[236500],\n",
      "        [187500],\n",
      "        [222500],\n",
      "        [131400],\n",
      "        [108000],\n",
      "        [163000],\n",
      "        [ 93500],\n",
      "        [239900],\n",
      "        [179000],\n",
      "        [190000]])\n",
      "tensor([[132000],\n",
      "        [142000],\n",
      "        [179000],\n",
      "        [175000],\n",
      "        [180000],\n",
      "        [299800],\n",
      "        [236000],\n",
      "        [265979],\n",
      "        [260400],\n",
      "        [ 98000]])\n",
      "tensor([[ 96500],\n",
      "        [162000],\n",
      "        [217000],\n",
      "        [275500],\n",
      "        [156000],\n",
      "        [172500],\n",
      "        [212000],\n",
      "        [158900],\n",
      "        [179400],\n",
      "        [290000]])\n",
      "tensor([[127500],\n",
      "        [100000],\n",
      "        [215200],\n",
      "        [337000],\n",
      "        [270000],\n",
      "        [264132],\n",
      "        [196500],\n",
      "        [160000],\n",
      "        [216837],\n",
      "        [538000]])\n",
      "tensor([[134900],\n",
      "        [102000],\n",
      "        [107000],\n",
      "        [114500],\n",
      "        [395000],\n",
      "        [162000],\n",
      "        [221500],\n",
      "        [142500],\n",
      "        [144000],\n",
      "        [135000]])\n",
      "tensor([[176000],\n",
      "        [175900],\n",
      "        [187100],\n",
      "        [165500],\n",
      "        [128000],\n",
      "        [161500],\n",
      "        [139000],\n",
      "        [233000],\n",
      "        [107900],\n",
      "        [187500]])\n",
      "tensor([[160200],\n",
      "        [146800],\n",
      "        [269790],\n",
      "        [225000],\n",
      "        [194500],\n",
      "        [171000],\n",
      "        [143500],\n",
      "        [110000],\n",
      "        [485000],\n",
      "        [175000]])\n",
      "tensor([[200000],\n",
      "        [109900],\n",
      "        [189000],\n",
      "        [582933],\n",
      "        [118000],\n",
      "        [227680],\n",
      "        [135500],\n",
      "        [223500],\n",
      "        [159950],\n",
      "        [106000]])\n",
      "tensor([[181000],\n",
      "        [144500],\n",
      "        [ 55993],\n",
      "        [157900],\n",
      "        [116000],\n",
      "        [224900],\n",
      "        [137000],\n",
      "        [271000],\n",
      "        [155000],\n",
      "        [224000]])\n",
      "tensor([[183000],\n",
      "        [ 93000],\n",
      "        [225000],\n",
      "        [139500],\n",
      "        [232600],\n",
      "        [385000],\n",
      "        [109500],\n",
      "        [189000],\n",
      "        [185000],\n",
      "        [147400]])\n",
      "tensor([[166000],\n",
      "        [151000],\n",
      "        [237000],\n",
      "        [167000],\n",
      "        [139950],\n",
      "        [128000],\n",
      "        [153500],\n",
      "        [100000],\n",
      "        [144000],\n",
      "        [130500]])\n",
      "tensor([[140000],\n",
      "        [157500],\n",
      "        [174900],\n",
      "        [141000],\n",
      "        [153900],\n",
      "        [171000],\n",
      "        [213000],\n",
      "        [133500],\n",
      "        [240000],\n",
      "        [187000]])\n",
      "tensor([[131500],\n",
      "        [215000],\n",
      "        [164000],\n",
      "        [158000],\n",
      "        [170000],\n",
      "        [127000],\n",
      "        [147000],\n",
      "        [174000],\n",
      "        [152000],\n",
      "        [250000]])\n",
      "tensor([[189950],\n",
      "        [131500],\n",
      "        [152000],\n",
      "        [132500],\n",
      "        [250580],\n",
      "        [148500],\n",
      "        [248900],\n",
      "        [129000],\n",
      "        [169000],\n",
      "        [236000]])\n",
      "tensor([[109500],\n",
      "        [200500],\n",
      "        [116000],\n",
      "        [133000],\n",
      "        [ 66500],\n",
      "        [303477],\n",
      "        [132250],\n",
      "        [350000],\n",
      "        [148000],\n",
      "        [136500]])\n",
      "tensor([[157000],\n",
      "        [187500],\n",
      "        [178000],\n",
      "        [118500],\n",
      "        [100000],\n",
      "        [328900],\n",
      "        [145000],\n",
      "        [135500],\n",
      "        [268000],\n",
      "        [149500]])\n",
      "tensor([[122900],\n",
      "        [172500],\n",
      "        [154500],\n",
      "        [165000],\n",
      "        [118858],\n",
      "        [140000],\n",
      "        [106500],\n",
      "        [142953],\n",
      "        [611657],\n",
      "        [135000]])\n",
      "tensor([[110000],\n",
      "        [153000],\n",
      "        [180000],\n",
      "        [240000],\n",
      "        [125500],\n",
      "        [128000],\n",
      "        [255000],\n",
      "        [250000],\n",
      "        [131000],\n",
      "        [174000]])\n",
      "tensor([[154300],\n",
      "        [143500],\n",
      "        [ 88000],\n",
      "        [145000],\n",
      "        [173733],\n",
      "        [ 75000],\n",
      "        [ 35311],\n",
      "        [135000],\n",
      "        [238000],\n",
      "        [176500]])\n",
      "tensor([[201000],\n",
      "        [145900],\n",
      "        [169990],\n",
      "        [193000],\n",
      "        [207500],\n",
      "        [175000],\n",
      "        [285000],\n",
      "        [176000],\n",
      "        [236500],\n",
      "        [222000]])\n",
      "tensor([[201000],\n",
      "        [117500],\n",
      "        [320000],\n",
      "        [190000],\n",
      "        [242000],\n",
      "        [ 79900],\n",
      "        [184900],\n",
      "        [253000],\n",
      "        [239799],\n",
      "        [244400]])\n",
      "tensor([[150900],\n",
      "        [214000],\n",
      "        [150000],\n",
      "        [143000],\n",
      "        [137500],\n",
      "        [124900],\n",
      "        [143000],\n",
      "        [270000],\n",
      "        [192500],\n",
      "        [197500]])\n",
      "tensor([[129000],\n",
      "        [119900],\n",
      "        [133900],\n",
      "        [172000],\n",
      "        [127500],\n",
      "        [145000],\n",
      "        [124000],\n",
      "        [132000],\n",
      "        [185000],\n",
      "        [155000]])\n",
      "tensor([[116500],\n",
      "        [272000],\n",
      "        [155000],\n",
      "        [239000],\n",
      "        [214900],\n",
      "        [178900],\n",
      "        [160000],\n",
      "        [135000],\n",
      "        [ 37900],\n",
      "        [140000]])\n",
      "tensor([[135000],\n",
      "        [173000],\n",
      "        [ 99500],\n",
      "        [182000],\n",
      "        [167500],\n",
      "        [165000],\n",
      "        [ 85500],\n",
      "        [199900],\n",
      "        [110000],\n",
      "        [139000]])\n",
      "tensor([[178400],\n",
      "        [336000],\n",
      "        [159895],\n",
      "        [255900],\n",
      "        [126000],\n",
      "        [125000],\n",
      "        [117000],\n",
      "        [395192],\n",
      "        [195000],\n",
      "        [197000]])\n",
      "tensor([[348000],\n",
      "        [168000],\n",
      "        [187000],\n",
      "        [173900],\n",
      "        [337500],\n",
      "        [121600],\n",
      "        [136500],\n",
      "        [185000],\n",
      "        [ 91000],\n",
      "        [206000]])\n",
      "tensor([[ 82000],\n",
      "        [ 86000],\n",
      "        [232000],\n",
      "        [136905],\n",
      "        [181000],\n",
      "        [149900],\n",
      "        [163500],\n",
      "        [ 88000],\n",
      "        [240000],\n",
      "        [102000]])\n",
      "tensor([[135000],\n",
      "        [100000],\n",
      "        [165000],\n",
      "        [ 85000],\n",
      "        [119200],\n",
      "        [227000],\n",
      "        [203000],\n",
      "        [187500],\n",
      "        [160000],\n",
      "        [213490]])\n",
      "tensor([[176000]])\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(data_loader['train']):\n",
    "    print(target)\n",
    "    next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        \n",
    "        # linear layer (330 -> 755001)\n",
    "        self.fc1 = nn.Linear(288, 755001)\n",
    "        \n",
    "        # linear layer (500 -> 250)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        \n",
    "        # linear layer (250 -> 125)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        \n",
    "        # linear layer (125 -> 1)\n",
    "        self.fc4 = nn.Linear(125, 755001)\n",
    "        \n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.175)\n",
    "        \n",
    "        # LogSoftmax\n",
    "        self.LSM = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        '''x = self.dropout(x)\n",
    "        \n",
    "        #h2\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h3\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h4\n",
    "        x = self.fc4(x)'''\n",
    "        x = self.LSM(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_HR = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_patho.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=288, out_features=755001, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=250, bias=True)\n",
       "  (fc3): Linear(in_features=250, out_features=125, bias=True)\n",
       "  (fc4): Linear(in_features=125, out_features=755001, bias=True)\n",
       "  (dropout): Dropout(p=0.175, inplace=False)\n",
       "  (LSM): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.SGD(model_HR.parameters(), lr=0.01, momentum = 0.9)\n",
    "\n",
    "VERSION = 'Test_version'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amallet\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 13.354946 \tValidation Loss: 13.064025 \tTime since the beginning 4.0 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (inf --> 13.064025).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 12.319686 \tValidation Loss: 12.414425 \tTime since the beginning 7.6 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (13.064025 --> 12.414425).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 11.227192 \tValidation Loss: 11.858389 \tTime since the beginning 11.4 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (12.414425 --> 11.858389).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 10.319078 \tValidation Loss: 11.434349 \tTime since the beginning 15.0 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (11.858389 --> 11.434349).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 9.565595 \tValidation Loss: 11.106926 \tTime since the beginning 18.7 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (11.434349 --> 11.106926).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 8.951899 \tValidation Loss: 10.871614 \tTime since the beginning 22.3 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (11.106926 --> 10.871614).  Saving model ...\n",
      "Epoch: 7 \tTraining Loss: 8.459228 \tValidation Loss: 10.705429 \tTime since the beginning 25.8 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (10.871614 --> 10.705429).  Saving model ...\n",
      "Epoch: 8 \tTraining Loss: 8.056779 \tValidation Loss: 10.580126 \tTime since the beginning 29.5 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (10.705429 --> 10.580126).  Saving model ...\n",
      "Epoch: 9 \tTraining Loss: 7.713463 \tValidation Loss: 10.484498 \tTime since the beginning 33.2 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (10.580126 --> 10.484498).  Saving model ...\n",
      "Epoch: 10 \tTraining Loss: 7.417033 \tValidation Loss: 10.412865 \tTime since the beginning 36.9 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (10.484498 --> 10.412865).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_res = train(10, data_loader, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train2(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 30834240840 bytes. Buy new RAM!\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-b9d63d21aee4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_res\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_loader2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_HR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-77c27900883e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(n_epochs, loaders, model, optimizer, criterion)\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-67-09dacec116b8>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# add 1st hidden layer, with relu activation function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         '''x = self.dropout(x)\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    545\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1369\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1371\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1372\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: [enforce fail at ..\\c10\\core\\CPUAllocator.cpp:72] data. DefaultCPUAllocator: not enough memory: you tried to allocate 30834240840 bytes. Buy new RAM!\n"
     ]
    }
   ],
   "source": [
    "model_res = train(6, data_loader2, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter_test = iter(data_loader['test'])\n",
    "print('data_iter\\n',dataiter_test)\n",
    "data_test = dataiter_test.next()\n",
    "data_test_data = data_test[0]\n",
    "print('image test data',data_test_data)\n",
    "\n",
    "model_test = model_HR\n",
    "model_test.load_state_dict(torch.load(VERSION))\n",
    "model_test = model_test.eval()\n",
    "\n",
    "\n",
    "out_fwd = model_test.forward(data_test_data)\n",
    "print('Result preditcion model on dataset:\\n {}\\n'.format(out_fwd))\n",
    "probs = torch.exp(out_fwd)\n",
    "print('probs\\n', probs)\n",
    "print(probs.max())\n",
    "print(probs.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
