{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_rows', None)\n",
    "train_csv = pd.read_csv(\"train.csv\")\n",
    "test_csv = pd.read_csv(\"test.csv\")\n",
    "samples_submission_csv = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id             1460\n",
      "SalePrice    755000\n",
      "dtype: int64\n",
      "before\n",
      "(1021, 289)\n",
      "(439, 289)\n",
      "(1021, 2)\n",
      "(439, 2)\n",
      "(1459, 289)\n",
      "(1459, 1)\n",
      "after\n",
      "(1021, 288)\n",
      "(439, 288)\n",
      "(1021, 1)\n",
      "(439, 1)\n",
      "(1459, 288)\n",
      "(1459, 1)\n"
     ]
    }
   ],
   "source": [
    "train_wo_SP = train_csv.drop(['SalePrice'], axis='columns')\n",
    "#print(train_wo_SP)\n",
    "# concat train and test features to have the same number of columns one the dummies features appear\n",
    "all_features = pd.concat([train_wo_SP, test_csv], keys=[\"train\", \"test\"])\n",
    "#print(all_features)\n",
    "# Normalize the numerical features\n",
    "numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "# creathe the dummies for train and test set\n",
    "all_features_dummies = pd.get_dummies(all_features)\n",
    "#print(all_features_dummies)\n",
    "\n",
    "# creation of the label of train dataset\n",
    "train_label1 = train_csv['Id']\n",
    "train_label2 = train_csv['SalePrice']\n",
    "train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "train_label['Id'] = train_label1\n",
    "train_label['SalePrice'] = train_label2\n",
    "print(train_label.max())\n",
    "\n",
    "#Split Data - creation of the Validation dataset\n",
    "train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "\n",
    "#Split label - creation of the validation labelset\n",
    "label_train = split_train_valid_data(train_label)\n",
    "label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "\n",
    "# creation of the test data set\n",
    "test_data = all_features_dummies.loc['test']\n",
    "\n",
    "# creation of an Empty label test\n",
    "label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "\n",
    "print('before')\n",
    "\n",
    "train_data = train_data.astype(np.float32)\n",
    "valid_data = valid_data.astype(np.float32)\n",
    "test_data = test_data.astype(np.float32)\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(label_train.shape)\n",
    "print(label_valid.shape)\n",
    "print(test_data.shape)\n",
    "print(label_test.shape)\n",
    "\n",
    "# remove 'ID' columns - data\n",
    "train_data = train_data.drop(['Id'], axis=1)\n",
    "train_data = train_data.fillna(0)\n",
    "valid_data = valid_data.drop(['Id'],axis=1)\n",
    "valid_data = valid_data.fillna(0)\n",
    "test_data = test_data.drop(['Id'], axis=1)\n",
    "test_data = test_data.fillna(0)\n",
    "\n",
    "# remove 'ID' column - label\n",
    "label_train = label_train.drop(['Id'], axis=1)\n",
    "label_valid = label_valid.drop(['Id'], axis=1)\n",
    "\n",
    "print('after')\n",
    "print(train_data.shape)\n",
    "print(valid_data.shape)\n",
    "print(label_train.shape)\n",
    "print(label_valid.shape)\n",
    "print(test_data.shape)\n",
    "print(label_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation\n",
    "\n",
    "class PrepareData(Dataset):\n",
    "\n",
    "    def __init__(self, In, Out):\n",
    "        if not torch.is_tensor(In):\n",
    "            In = In.to_numpy()\n",
    "            self.In = torch.from_numpy(In)\n",
    "        if not torch.is_tensor(Out):\n",
    "            Out = Out.to_numpy()\n",
    "            self.Out = torch.from_numpy(Out)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.In)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.In[idx], self.Out[idx]\n",
    "        \n",
    "\n",
    "\n",
    "data_dataset = {x: PrepareData(In=train_data if x == 'train'\n",
    "                               else valid_data if x =='valid'\n",
    "                               else test_data, \n",
    "                               Out=label_train if x == 'train'\n",
    "                               else label_valid if x == 'valid'\n",
    "                               else label_test)\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader = {x: torch.utils.data.DataLoader(data_dataset[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([288])\n",
      "\n",
      "Target at the first row:  tensor([208500])\n",
      "Target format at the first row: tensor([208500])\n",
      "Target format at the first row: torch.Size([1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "img, lab_target = data_dataset['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file_data, csv_file_test, id_col, target_col, data='train'):\n",
    "        self.data_train= pd.read_csv(csv_file_data)\n",
    "        self.data_test = pd.read_csv(csv_file_test)\n",
    "        self.id        = id_col\n",
    "        self.target    = target_col\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        if self.data == 'train':\n",
    "            return len(self.data_train)\n",
    "        else:\n",
    "            return len(self.data_test)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # remove the target column\n",
    "        train_wo_SP = self.data_train.drop(self.target, axis='columns')\n",
    "        # concat train and test features to have the same number of columns one the dummies features appear\n",
    "        all_features = pd.concat([train_wo_SP, self.data_test], keys=[\"train\", \"test\"])\n",
    "        # Normalize the numerical features\n",
    "        numeric_features = all_features.dtypes[all_features.dtypes != 'object'].index\n",
    "        all_features[numeric_features] = all_features[numeric_features].apply(lambda x: (x - x.mean()) / (x.std()))\n",
    "        # creathe the dummies for train and test set\n",
    "        all_features_dummies = pd.get_dummies(all_features)\n",
    "        \n",
    "        # creation of the label of train dataset\n",
    "        train_label1 = train_csv['Id']\n",
    "        train_label2 = train_csv['SalePrice']\n",
    "        train_label = pd.DataFrame(columns = ['Id', 'SalePrice'])\n",
    "        train_label['Id'] = train_label1\n",
    "        train_label['SalePrice'] = train_label2\n",
    "\n",
    "        #Split Data - creation of the Validation dataset\n",
    "        train_data = split_train_valid_data(all_features_dummies.loc['train'])\n",
    "        valid_data = all_features_dummies.loc['train'].iloc[max(train_data.index+1):]\n",
    "        #Split label - creation of the validation labelset\n",
    "        label_train = split_train_valid_data(train_label)\n",
    "        label_valid = train_label.iloc[max(train_data.index+1):]\n",
    "         \n",
    "        # creation of the test data set\n",
    "        test_data = all_features_dummies.loc['test']\n",
    "        \n",
    "        # creation of an Empty label test\n",
    "        label_test = pd.DataFrame(np.empty((test_data.shape[0],1)))\n",
    "        \n",
    "        # remove 'ID' columns - data\n",
    "        train_data = train_data.drop(['Id'], axis=1)\n",
    "        valid_data = valid_data.drop(['Id'],axis=1)\n",
    "        test_data = test_data.drop(['Id'], axis=1)\n",
    "        \n",
    "        # remove 'ID' column - label\n",
    "        label_train = label_train.drop(['Id'], axis=1)\n",
    "        label_valid = label_valid.drop(['Id'], axis=1)\n",
    "            \n",
    "        # data preparation\n",
    "        if self.data == 'train':\n",
    "            use_data = train_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'valid':\n",
    "            use_data = valid_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "        elif self.data == 'test':\n",
    "            use_data = test_data.to_numpy()\n",
    "            use_data = torch.from_numpy(use_data)\n",
    "            \n",
    "        # label preparation\n",
    "        if self.data == 'train':\n",
    "            label_data = label_train.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'valid':\n",
    "            label_data = label_valid.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        elif self.data == 'test':\n",
    "            label_data = label_test.to_numpy()\n",
    "            label_data = torch.from_numpy(label_data)\n",
    "        \n",
    "        return use_data, label_data\n",
    "\n",
    "params = {\n",
    "    'id_col':'Id',  \n",
    "    'target_col': ['SalePrice'],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dataset2 = {x: CustomDataset(csv_file_data=\"train.csv\" , \n",
    "                                   csv_file_test=\"test.csv\", \n",
    "                                   **params, \n",
    "                                   data='train' if x == 'train'\n",
    "                                   else 'valid' if x =='valid'\n",
    "                                   else 'test')\n",
    "                for x in ['train', 'valid', 'test']}\n",
    "\n",
    "data_loader2 = {x: torch.utils.data.DataLoader(data_dataset2[x], batch_size = 10,  shuffle=False) \n",
    "               for x in ['train', 'valid', 'test']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING\n",
      "DATASET\n",
      "image at the first row:  torch.Size([1021, 288])\n",
      "image at the first row:  <class 'torch.Tensor'>\n",
      "image size at the first row: torch.Size([1021, 288])\n",
      "\n",
      "Target at the first row:  tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        ...,\n",
      "        [160000],\n",
      "        [213490],\n",
      "        [176000]])\n",
      "Target format at the first row: torch.Size([1021, 1])\n",
      "\n",
      "Train Loader type\n",
      "<class 'torch.utils.data.dataloader._SingleProcessDataLoaderIter'>\n",
      "\n",
      "DATALOADER\n",
      "images type on batch size = <class 'torch.Tensor'>\n",
      "images shape on batch size =  torch.Size([10, 1021, 288])\n",
      "\n",
      "Targett type on batch size\n",
      "Target type on batch size = <class 'torch.Tensor'>\n",
      "Target shape on batch size =  torch.Size([10, 1021, 1])\n"
     ]
    }
   ],
   "source": [
    "print('TRAINING')\n",
    "img, lab_target = data_dataset2['train'].__getitem__(0)\n",
    "\n",
    "print('DATASET')\n",
    "print('image at the first row: ', img.shape)\n",
    "print('image at the first row: ', type(img))\n",
    "print('image size at the first row: {}'.format(img.size()))\n",
    "print('\\nTarget at the first row: ', lab_target)\n",
    "print('Target format at the first row: {}'.format(lab_target))\n",
    "print('Target format at the first row: {}'.format(lab_target.shape))\n",
    "\n",
    "\n",
    "print()\n",
    "print('Train Loader type')\n",
    "train_iter = iter(data_loader2['train'])\n",
    "print(type(train_iter))\n",
    "\n",
    "images, labels_target = train_iter.next()\n",
    "print()\n",
    "print('DATALOADER')\n",
    "print('images type on batch size = {}'.format(type(images)))\n",
    "print('images shape on batch size = ', images.shape)\n",
    "print('\\nTargett type on batch size')\n",
    "print('Target type on batch size = {}'.format(type(labels_target)))\n",
    "print('Target shape on batch size = ', labels_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[208500],\n",
      "        [181500],\n",
      "        [223500],\n",
      "        [140000],\n",
      "        [250000],\n",
      "        [143000],\n",
      "        [307000],\n",
      "        [200000],\n",
      "        [129900],\n",
      "        [118000]])\n",
      "tensor([[129500],\n",
      "        [345000],\n",
      "        [144000],\n",
      "        [279500],\n",
      "        [157000],\n",
      "        [132000],\n",
      "        [149000],\n",
      "        [ 90000],\n",
      "        [159000],\n",
      "        [139000]])\n",
      "tensor([[325300],\n",
      "        [139400],\n",
      "        [230000],\n",
      "        [129900],\n",
      "        [154000],\n",
      "        [256300],\n",
      "        [134800],\n",
      "        [306000],\n",
      "        [207500],\n",
      "        [ 68500]])\n",
      "tensor([[ 40000],\n",
      "        [149350],\n",
      "        [179900],\n",
      "        [165500],\n",
      "        [277500],\n",
      "        [309000],\n",
      "        [145000],\n",
      "        [153000],\n",
      "        [109000],\n",
      "        [ 82000]])\n",
      "tensor([[160000],\n",
      "        [170000],\n",
      "        [144000],\n",
      "        [130250],\n",
      "        [141000],\n",
      "        [319900],\n",
      "        [239686],\n",
      "        [249700],\n",
      "        [113000],\n",
      "        [127000]])\n",
      "tensor([[177000],\n",
      "        [114500],\n",
      "        [110000],\n",
      "        [385000],\n",
      "        [130000],\n",
      "        [180500],\n",
      "        [172500],\n",
      "        [196500],\n",
      "        [438780],\n",
      "        [124900]])\n",
      "tensor([[158000],\n",
      "        [101000],\n",
      "        [202500],\n",
      "        [140000],\n",
      "        [219500],\n",
      "        [317000],\n",
      "        [180000],\n",
      "        [226000],\n",
      "        [ 80000],\n",
      "        [225000]])\n",
      "tensor([[244000],\n",
      "        [129500],\n",
      "        [185000],\n",
      "        [144900],\n",
      "        [107400],\n",
      "        [ 91000],\n",
      "        [135750],\n",
      "        [127000],\n",
      "        [136500],\n",
      "        [110000]])\n",
      "tensor([[193500],\n",
      "        [153500],\n",
      "        [245000],\n",
      "        [126500],\n",
      "        [168500],\n",
      "        [260000],\n",
      "        [174000],\n",
      "        [164500],\n",
      "        [ 85000],\n",
      "        [123600]])\n",
      "tensor([[109900],\n",
      "        [ 98600],\n",
      "        [163500],\n",
      "        [133900],\n",
      "        [204750],\n",
      "        [185000],\n",
      "        [214000],\n",
      "        [ 94750],\n",
      "        [ 83000],\n",
      "        [128950]])\n",
      "tensor([[205000],\n",
      "        [178000],\n",
      "        [118964],\n",
      "        [198900],\n",
      "        [169500],\n",
      "        [250000],\n",
      "        [100000],\n",
      "        [115000],\n",
      "        [115000],\n",
      "        [190000]])\n",
      "tensor([[136900],\n",
      "        [180000],\n",
      "        [383970],\n",
      "        [217000],\n",
      "        [259500],\n",
      "        [176000],\n",
      "        [139000],\n",
      "        [155000],\n",
      "        [320000],\n",
      "        [163990]])\n",
      "tensor([[180000],\n",
      "        [100000],\n",
      "        [136000],\n",
      "        [153900],\n",
      "        [181000],\n",
      "        [ 84500],\n",
      "        [128000],\n",
      "        [ 87000],\n",
      "        [155000],\n",
      "        [150000]])\n",
      "tensor([[226000],\n",
      "        [244000],\n",
      "        [150750],\n",
      "        [220000],\n",
      "        [180000],\n",
      "        [174000],\n",
      "        [143000],\n",
      "        [171000],\n",
      "        [230000],\n",
      "        [231500]])\n",
      "tensor([[115000],\n",
      "        [260000],\n",
      "        [166000],\n",
      "        [204000],\n",
      "        [125000],\n",
      "        [130000],\n",
      "        [105000],\n",
      "        [222500],\n",
      "        [141000],\n",
      "        [115000]])\n",
      "tensor([[122000],\n",
      "        [372402],\n",
      "        [190000],\n",
      "        [235000],\n",
      "        [125000],\n",
      "        [ 79000],\n",
      "        [109500],\n",
      "        [269500],\n",
      "        [254900],\n",
      "        [320000]])\n",
      "tensor([[162500],\n",
      "        [412500],\n",
      "        [220000],\n",
      "        [103200],\n",
      "        [152000],\n",
      "        [127500],\n",
      "        [190000],\n",
      "        [325624],\n",
      "        [183500],\n",
      "        [228000]])\n",
      "tensor([[128500],\n",
      "        [215000],\n",
      "        [239000],\n",
      "        [163000],\n",
      "        [184000],\n",
      "        [243000],\n",
      "        [211000],\n",
      "        [172500],\n",
      "        [501837],\n",
      "        [100000]])\n",
      "tensor([[177000],\n",
      "        [200100],\n",
      "        [120000],\n",
      "        [200000],\n",
      "        [127000],\n",
      "        [475000],\n",
      "        [173000],\n",
      "        [135000],\n",
      "        [153337],\n",
      "        [286000]])\n",
      "tensor([[315000],\n",
      "        [184000],\n",
      "        [192000],\n",
      "        [130000],\n",
      "        [127000],\n",
      "        [148500],\n",
      "        [311872],\n",
      "        [235000],\n",
      "        [104000],\n",
      "        [274900]])\n",
      "tensor([[140000],\n",
      "        [171500],\n",
      "        [112000],\n",
      "        [149000],\n",
      "        [110000],\n",
      "        [180500],\n",
      "        [143900],\n",
      "        [141000],\n",
      "        [277000],\n",
      "        [145000]])\n",
      "tensor([[ 98000],\n",
      "        [186000],\n",
      "        [252678],\n",
      "        [156000],\n",
      "        [161750],\n",
      "        [134450],\n",
      "        [210000],\n",
      "        [107000],\n",
      "        [311500],\n",
      "        [167240]])\n",
      "tensor([[204900],\n",
      "        [200000],\n",
      "        [179900],\n",
      "        [ 97000],\n",
      "        [386250],\n",
      "        [112000],\n",
      "        [290000],\n",
      "        [106000],\n",
      "        [125000],\n",
      "        [192500]])\n",
      "tensor([[148000],\n",
      "        [403000],\n",
      "        [ 94500],\n",
      "        [128200],\n",
      "        [216500],\n",
      "        [ 89500],\n",
      "        [185500],\n",
      "        [194500],\n",
      "        [318000],\n",
      "        [113000]])\n",
      "tensor([[262500],\n",
      "        [110500],\n",
      "        [ 79000],\n",
      "        [120000],\n",
      "        [205000],\n",
      "        [241500],\n",
      "        [137000],\n",
      "        [140000],\n",
      "        [180000],\n",
      "        [277000]])\n",
      "tensor([[ 76500],\n",
      "        [235000],\n",
      "        [173000],\n",
      "        [158000],\n",
      "        [145000],\n",
      "        [230000],\n",
      "        [207500],\n",
      "        [220000],\n",
      "        [231500],\n",
      "        [ 97000]])\n",
      "tensor([[176000],\n",
      "        [276000],\n",
      "        [151000],\n",
      "        [130000],\n",
      "        [ 73000],\n",
      "        [175500],\n",
      "        [185000],\n",
      "        [179500],\n",
      "        [120500],\n",
      "        [148000]])\n",
      "tensor([[266000],\n",
      "        [241500],\n",
      "        [290000],\n",
      "        [139000],\n",
      "        [124500],\n",
      "        [205000],\n",
      "        [201000],\n",
      "        [141000],\n",
      "        [415298],\n",
      "        [192000]])\n",
      "tensor([[228500],\n",
      "        [185000],\n",
      "        [207500],\n",
      "        [244600],\n",
      "        [179200],\n",
      "        [164700],\n",
      "        [159000],\n",
      "        [ 88000],\n",
      "        [122000],\n",
      "        [153575]])\n",
      "tensor([[233230],\n",
      "        [135900],\n",
      "        [131000],\n",
      "        [235000],\n",
      "        [167000],\n",
      "        [142500],\n",
      "        [152000],\n",
      "        [239000],\n",
      "        [175000],\n",
      "        [158500]])\n",
      "tensor([[157000],\n",
      "        [267000],\n",
      "        [205000],\n",
      "        [149900],\n",
      "        [295000],\n",
      "        [305900],\n",
      "        [225000],\n",
      "        [ 89500],\n",
      "        [ 82500],\n",
      "        [360000]])\n",
      "tensor([[165600],\n",
      "        [132000],\n",
      "        [119900],\n",
      "        [375000],\n",
      "        [178000],\n",
      "        [188500],\n",
      "        [260000],\n",
      "        [270000],\n",
      "        [260000],\n",
      "        [187500]])\n",
      "tensor([[342643],\n",
      "        [354000],\n",
      "        [301000],\n",
      "        [126175],\n",
      "        [242000],\n",
      "        [ 87000],\n",
      "        [324000],\n",
      "        [145250],\n",
      "        [214500],\n",
      "        [ 78000]])\n",
      "tensor([[119000],\n",
      "        [139000],\n",
      "        [284000],\n",
      "        [207000],\n",
      "        [192000],\n",
      "        [228950],\n",
      "        [377426],\n",
      "        [214000],\n",
      "        [202500],\n",
      "        [155000]])\n",
      "tensor([[202900],\n",
      "        [ 82000],\n",
      "        [ 87500],\n",
      "        [266000],\n",
      "        [ 85000],\n",
      "        [140200],\n",
      "        [151500],\n",
      "        [157500],\n",
      "        [154000],\n",
      "        [437154]])\n",
      "tensor([[318061],\n",
      "        [190000],\n",
      "        [ 95000],\n",
      "        [105900],\n",
      "        [140000],\n",
      "        [177500],\n",
      "        [173000],\n",
      "        [134000],\n",
      "        [130000],\n",
      "        [280000]])\n",
      "tensor([[156000],\n",
      "        [145000],\n",
      "        [198500],\n",
      "        [118000],\n",
      "        [190000],\n",
      "        [147000],\n",
      "        [159000],\n",
      "        [165000],\n",
      "        [132000],\n",
      "        [162000]])\n",
      "tensor([[172400],\n",
      "        [134432],\n",
      "        [125000],\n",
      "        [123000],\n",
      "        [219500],\n",
      "        [ 61000],\n",
      "        [148000],\n",
      "        [340000],\n",
      "        [394432],\n",
      "        [179000]])\n",
      "tensor([[127000],\n",
      "        [187750],\n",
      "        [213500],\n",
      "        [ 76000],\n",
      "        [240000],\n",
      "        [192000],\n",
      "        [ 81000],\n",
      "        [125000],\n",
      "        [191000],\n",
      "        [426000]])\n",
      "tensor([[119000],\n",
      "        [215000],\n",
      "        [106500],\n",
      "        [100000],\n",
      "        [109000],\n",
      "        [129000],\n",
      "        [123000],\n",
      "        [169500],\n",
      "        [ 67000],\n",
      "        [241000]])\n",
      "tensor([[245500],\n",
      "        [164990],\n",
      "        [108000],\n",
      "        [258000],\n",
      "        [168000],\n",
      "        [150000],\n",
      "        [115000],\n",
      "        [177000],\n",
      "        [280000],\n",
      "        [339750]])\n",
      "tensor([[ 60000],\n",
      "        [145000],\n",
      "        [222000],\n",
      "        [115000],\n",
      "        [228000],\n",
      "        [181134],\n",
      "        [149500],\n",
      "        [239000],\n",
      "        [126000],\n",
      "        [142000]])\n",
      "tensor([[206300],\n",
      "        [215000],\n",
      "        [113000],\n",
      "        [315000],\n",
      "        [139000],\n",
      "        [135000],\n",
      "        [275000],\n",
      "        [109008],\n",
      "        [195400],\n",
      "        [175000]])\n",
      "tensor([[ 85400],\n",
      "        [ 79900],\n",
      "        [122500],\n",
      "        [181000],\n",
      "        [ 81000],\n",
      "        [212000],\n",
      "        [116000],\n",
      "        [119000],\n",
      "        [ 90350],\n",
      "        [110000]])\n",
      "tensor([[555000],\n",
      "        [118000],\n",
      "        [162900],\n",
      "        [172500],\n",
      "        [210000],\n",
      "        [127500],\n",
      "        [190000],\n",
      "        [199900],\n",
      "        [119500],\n",
      "        [120000]])\n",
      "tensor([[110000],\n",
      "        [280000],\n",
      "        [204000],\n",
      "        [210000],\n",
      "        [188000],\n",
      "        [175500],\n",
      "        [ 98000],\n",
      "        [256000],\n",
      "        [161000],\n",
      "        [110000]])\n",
      "tensor([[263435],\n",
      "        [155000],\n",
      "        [ 62383],\n",
      "        [188700],\n",
      "        [124000],\n",
      "        [178740],\n",
      "        [167000],\n",
      "        [146500],\n",
      "        [250000],\n",
      "        [187000]])\n",
      "tensor([[212000],\n",
      "        [190000],\n",
      "        [148000],\n",
      "        [440000],\n",
      "        [251000],\n",
      "        [132500],\n",
      "        [208900],\n",
      "        [380000],\n",
      "        [297000],\n",
      "        [ 89471]])\n",
      "tensor([[326000],\n",
      "        [374000],\n",
      "        [155000],\n",
      "        [164000],\n",
      "        [132500],\n",
      "        [147000],\n",
      "        [156000],\n",
      "        [175000],\n",
      "        [160000],\n",
      "        [ 86000]])\n",
      "tensor([[115000],\n",
      "        [133000],\n",
      "        [172785],\n",
      "        [155000],\n",
      "        [ 91300],\n",
      "        [ 34900],\n",
      "        [430000],\n",
      "        [184000],\n",
      "        [130000],\n",
      "        [120000]])\n",
      "tensor([[113000],\n",
      "        [226700],\n",
      "        [140000],\n",
      "        [289000],\n",
      "        [147000],\n",
      "        [124500],\n",
      "        [215000],\n",
      "        [208300],\n",
      "        [161000],\n",
      "        [124500]])\n",
      "tensor([[164900],\n",
      "        [202665],\n",
      "        [129900],\n",
      "        [134000],\n",
      "        [ 96500],\n",
      "        [402861],\n",
      "        [158000],\n",
      "        [265000],\n",
      "        [211000],\n",
      "        [234000]])\n",
      "tensor([[106250],\n",
      "        [150000],\n",
      "        [159000],\n",
      "        [184750],\n",
      "        [315750],\n",
      "        [176000],\n",
      "        [132000],\n",
      "        [446261],\n",
      "        [ 86000],\n",
      "        [200624]])\n",
      "tensor([[175000],\n",
      "        [128000],\n",
      "        [107500],\n",
      "        [ 39300],\n",
      "        [178000],\n",
      "        [107500],\n",
      "        [188000],\n",
      "        [111250],\n",
      "        [158000],\n",
      "        [272000]])\n",
      "tensor([[315000],\n",
      "        [248000],\n",
      "        [213250],\n",
      "        [133000],\n",
      "        [179665],\n",
      "        [229000],\n",
      "        [210000],\n",
      "        [129500],\n",
      "        [125000],\n",
      "        [263000]])\n",
      "tensor([[140000],\n",
      "        [112500],\n",
      "        [255500],\n",
      "        [108000],\n",
      "        [284000],\n",
      "        [113000],\n",
      "        [141000],\n",
      "        [108000],\n",
      "        [175000],\n",
      "        [234000]])\n",
      "tensor([[121500],\n",
      "        [170000],\n",
      "        [108000],\n",
      "        [185000],\n",
      "        [268000],\n",
      "        [128000],\n",
      "        [325000],\n",
      "        [214000],\n",
      "        [316600],\n",
      "        [135960]])\n",
      "tensor([[142600],\n",
      "        [120000],\n",
      "        [224500],\n",
      "        [170000],\n",
      "        [139000],\n",
      "        [118500],\n",
      "        [145000],\n",
      "        [164500],\n",
      "        [146000],\n",
      "        [131500]])\n",
      "tensor([[181900],\n",
      "        [253293],\n",
      "        [118500],\n",
      "        [325000],\n",
      "        [133000],\n",
      "        [369900],\n",
      "        [130000],\n",
      "        [137000],\n",
      "        [143000],\n",
      "        [ 79500]])\n",
      "tensor([[185900],\n",
      "        [451950],\n",
      "        [138000],\n",
      "        [140000],\n",
      "        [110000],\n",
      "        [319000],\n",
      "        [114504],\n",
      "        [194201],\n",
      "        [217500],\n",
      "        [151000]])\n",
      "tensor([[275000],\n",
      "        [141000],\n",
      "        [220000],\n",
      "        [151000],\n",
      "        [221000],\n",
      "        [205000],\n",
      "        [152000],\n",
      "        [225000],\n",
      "        [359100],\n",
      "        [118500]])\n",
      "tensor([[313000],\n",
      "        [148000],\n",
      "        [261500],\n",
      "        [147000],\n",
      "        [ 75500],\n",
      "        [137500],\n",
      "        [183200],\n",
      "        [105500],\n",
      "        [314813],\n",
      "        [305000]])\n",
      "tensor([[ 67000],\n",
      "        [240000],\n",
      "        [135000],\n",
      "        [168500],\n",
      "        [165150],\n",
      "        [160000],\n",
      "        [139900],\n",
      "        [153000],\n",
      "        [135000],\n",
      "        [168500]])\n",
      "tensor([[124000],\n",
      "        [209500],\n",
      "        [ 82500],\n",
      "        [139400],\n",
      "        [144000],\n",
      "        [200000],\n",
      "        [ 60000],\n",
      "        [ 93000],\n",
      "        [ 85000],\n",
      "        [264561]])\n",
      "tensor([[274000],\n",
      "        [226000],\n",
      "        [345000],\n",
      "        [152000],\n",
      "        [370878],\n",
      "        [143250],\n",
      "        [ 98300],\n",
      "        [155000],\n",
      "        [155000],\n",
      "        [ 84500]])\n",
      "tensor([[205950],\n",
      "        [108000],\n",
      "        [191000],\n",
      "        [135000],\n",
      "        [350000],\n",
      "        [ 88000],\n",
      "        [145500],\n",
      "        [149000],\n",
      "        [ 97500],\n",
      "        [167000]])\n",
      "tensor([[197900],\n",
      "        [402000],\n",
      "        [110000],\n",
      "        [137500],\n",
      "        [423000],\n",
      "        [230500],\n",
      "        [129000],\n",
      "        [193500],\n",
      "        [168000],\n",
      "        [137500]])\n",
      "tensor([[173500],\n",
      "        [103600],\n",
      "        [165000],\n",
      "        [257500],\n",
      "        [140000],\n",
      "        [148500],\n",
      "        [ 87000],\n",
      "        [109500],\n",
      "        [372500],\n",
      "        [128500]])\n",
      "tensor([[143000],\n",
      "        [159434],\n",
      "        [173000],\n",
      "        [285000],\n",
      "        [221000],\n",
      "        [207500],\n",
      "        [227875],\n",
      "        [148800],\n",
      "        [392000],\n",
      "        [194700]])\n",
      "tensor([[141000],\n",
      "        [755000],\n",
      "        [335000],\n",
      "        [108480],\n",
      "        [141500],\n",
      "        [176000],\n",
      "        [ 89000],\n",
      "        [123500],\n",
      "        [138500],\n",
      "        [196000]])\n",
      "tensor([[312500],\n",
      "        [140000],\n",
      "        [361919],\n",
      "        [140000],\n",
      "        [213000],\n",
      "        [ 55000],\n",
      "        [302000],\n",
      "        [254000],\n",
      "        [179540],\n",
      "        [109900]])\n",
      "tensor([[ 52000],\n",
      "        [102776],\n",
      "        [189000],\n",
      "        [129000],\n",
      "        [130500],\n",
      "        [165000],\n",
      "        [159500],\n",
      "        [157000],\n",
      "        [341000],\n",
      "        [128500]])\n",
      "tensor([[275000],\n",
      "        [143000],\n",
      "        [124500],\n",
      "        [135000],\n",
      "        [320000],\n",
      "        [120500],\n",
      "        [222000],\n",
      "        [194500],\n",
      "        [110000],\n",
      "        [103000]])\n",
      "tensor([[236500],\n",
      "        [187500],\n",
      "        [222500],\n",
      "        [131400],\n",
      "        [108000],\n",
      "        [163000],\n",
      "        [ 93500],\n",
      "        [239900],\n",
      "        [179000],\n",
      "        [190000]])\n",
      "tensor([[132000],\n",
      "        [142000],\n",
      "        [179000],\n",
      "        [175000],\n",
      "        [180000],\n",
      "        [299800],\n",
      "        [236000],\n",
      "        [265979],\n",
      "        [260400],\n",
      "        [ 98000]])\n",
      "tensor([[ 96500],\n",
      "        [162000],\n",
      "        [217000],\n",
      "        [275500],\n",
      "        [156000],\n",
      "        [172500],\n",
      "        [212000],\n",
      "        [158900],\n",
      "        [179400],\n",
      "        [290000]])\n",
      "tensor([[127500],\n",
      "        [100000],\n",
      "        [215200],\n",
      "        [337000],\n",
      "        [270000],\n",
      "        [264132],\n",
      "        [196500],\n",
      "        [160000],\n",
      "        [216837],\n",
      "        [538000]])\n",
      "tensor([[134900],\n",
      "        [102000],\n",
      "        [107000],\n",
      "        [114500],\n",
      "        [395000],\n",
      "        [162000],\n",
      "        [221500],\n",
      "        [142500],\n",
      "        [144000],\n",
      "        [135000]])\n",
      "tensor([[176000],\n",
      "        [175900],\n",
      "        [187100],\n",
      "        [165500],\n",
      "        [128000],\n",
      "        [161500],\n",
      "        [139000],\n",
      "        [233000],\n",
      "        [107900],\n",
      "        [187500]])\n",
      "tensor([[160200],\n",
      "        [146800],\n",
      "        [269790],\n",
      "        [225000],\n",
      "        [194500],\n",
      "        [171000],\n",
      "        [143500],\n",
      "        [110000],\n",
      "        [485000],\n",
      "        [175000]])\n",
      "tensor([[200000],\n",
      "        [109900],\n",
      "        [189000],\n",
      "        [582933],\n",
      "        [118000],\n",
      "        [227680],\n",
      "        [135500],\n",
      "        [223500],\n",
      "        [159950],\n",
      "        [106000]])\n",
      "tensor([[181000],\n",
      "        [144500],\n",
      "        [ 55993],\n",
      "        [157900],\n",
      "        [116000],\n",
      "        [224900],\n",
      "        [137000],\n",
      "        [271000],\n",
      "        [155000],\n",
      "        [224000]])\n",
      "tensor([[183000],\n",
      "        [ 93000],\n",
      "        [225000],\n",
      "        [139500],\n",
      "        [232600],\n",
      "        [385000],\n",
      "        [109500],\n",
      "        [189000],\n",
      "        [185000],\n",
      "        [147400]])\n",
      "tensor([[166000],\n",
      "        [151000],\n",
      "        [237000],\n",
      "        [167000],\n",
      "        [139950],\n",
      "        [128000],\n",
      "        [153500],\n",
      "        [100000],\n",
      "        [144000],\n",
      "        [130500]])\n",
      "tensor([[140000],\n",
      "        [157500],\n",
      "        [174900],\n",
      "        [141000],\n",
      "        [153900],\n",
      "        [171000],\n",
      "        [213000],\n",
      "        [133500],\n",
      "        [240000],\n",
      "        [187000]])\n",
      "tensor([[131500],\n",
      "        [215000],\n",
      "        [164000],\n",
      "        [158000],\n",
      "        [170000],\n",
      "        [127000],\n",
      "        [147000],\n",
      "        [174000],\n",
      "        [152000],\n",
      "        [250000]])\n",
      "tensor([[189950],\n",
      "        [131500],\n",
      "        [152000],\n",
      "        [132500],\n",
      "        [250580],\n",
      "        [148500],\n",
      "        [248900],\n",
      "        [129000],\n",
      "        [169000],\n",
      "        [236000]])\n",
      "tensor([[109500],\n",
      "        [200500],\n",
      "        [116000],\n",
      "        [133000],\n",
      "        [ 66500],\n",
      "        [303477],\n",
      "        [132250],\n",
      "        [350000],\n",
      "        [148000],\n",
      "        [136500]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[157000],\n",
      "        [187500],\n",
      "        [178000],\n",
      "        [118500],\n",
      "        [100000],\n",
      "        [328900],\n",
      "        [145000],\n",
      "        [135500],\n",
      "        [268000],\n",
      "        [149500]])\n",
      "tensor([[122900],\n",
      "        [172500],\n",
      "        [154500],\n",
      "        [165000],\n",
      "        [118858],\n",
      "        [140000],\n",
      "        [106500],\n",
      "        [142953],\n",
      "        [611657],\n",
      "        [135000]])\n",
      "tensor([[110000],\n",
      "        [153000],\n",
      "        [180000],\n",
      "        [240000],\n",
      "        [125500],\n",
      "        [128000],\n",
      "        [255000],\n",
      "        [250000],\n",
      "        [131000],\n",
      "        [174000]])\n",
      "tensor([[154300],\n",
      "        [143500],\n",
      "        [ 88000],\n",
      "        [145000],\n",
      "        [173733],\n",
      "        [ 75000],\n",
      "        [ 35311],\n",
      "        [135000],\n",
      "        [238000],\n",
      "        [176500]])\n",
      "tensor([[201000],\n",
      "        [145900],\n",
      "        [169990],\n",
      "        [193000],\n",
      "        [207500],\n",
      "        [175000],\n",
      "        [285000],\n",
      "        [176000],\n",
      "        [236500],\n",
      "        [222000]])\n",
      "tensor([[201000],\n",
      "        [117500],\n",
      "        [320000],\n",
      "        [190000],\n",
      "        [242000],\n",
      "        [ 79900],\n",
      "        [184900],\n",
      "        [253000],\n",
      "        [239799],\n",
      "        [244400]])\n",
      "tensor([[150900],\n",
      "        [214000],\n",
      "        [150000],\n",
      "        [143000],\n",
      "        [137500],\n",
      "        [124900],\n",
      "        [143000],\n",
      "        [270000],\n",
      "        [192500],\n",
      "        [197500]])\n",
      "tensor([[129000],\n",
      "        [119900],\n",
      "        [133900],\n",
      "        [172000],\n",
      "        [127500],\n",
      "        [145000],\n",
      "        [124000],\n",
      "        [132000],\n",
      "        [185000],\n",
      "        [155000]])\n",
      "tensor([[116500],\n",
      "        [272000],\n",
      "        [155000],\n",
      "        [239000],\n",
      "        [214900],\n",
      "        [178900],\n",
      "        [160000],\n",
      "        [135000],\n",
      "        [ 37900],\n",
      "        [140000]])\n",
      "tensor([[135000],\n",
      "        [173000],\n",
      "        [ 99500],\n",
      "        [182000],\n",
      "        [167500],\n",
      "        [165000],\n",
      "        [ 85500],\n",
      "        [199900],\n",
      "        [110000],\n",
      "        [139000]])\n",
      "tensor([[178400],\n",
      "        [336000],\n",
      "        [159895],\n",
      "        [255900],\n",
      "        [126000],\n",
      "        [125000],\n",
      "        [117000],\n",
      "        [395192],\n",
      "        [195000],\n",
      "        [197000]])\n",
      "tensor([[348000],\n",
      "        [168000],\n",
      "        [187000],\n",
      "        [173900],\n",
      "        [337500],\n",
      "        [121600],\n",
      "        [136500],\n",
      "        [185000],\n",
      "        [ 91000],\n",
      "        [206000]])\n",
      "tensor([[ 82000],\n",
      "        [ 86000],\n",
      "        [232000],\n",
      "        [136905],\n",
      "        [181000],\n",
      "        [149900],\n",
      "        [163500],\n",
      "        [ 88000],\n",
      "        [240000],\n",
      "        [102000]])\n",
      "tensor([[135000],\n",
      "        [100000],\n",
      "        [165000],\n",
      "        [ 85000],\n",
      "        [119200],\n",
      "        [227000],\n",
      "        [203000],\n",
      "        [187500],\n",
      "        [160000],\n",
      "        [213490]])\n",
      "tensor([[176000]])\n"
     ]
    }
   ],
   "source": [
    "for idx, (data, target) in enumerate(data_loader['train']):\n",
    "    print(target)\n",
    "    next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    ### TODO: choose an architecture, and complete the class\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        ## Define layers of a CNN\n",
    "        \n",
    "        # linear layer (330 -> 500)\n",
    "        self.fc1 = nn.Linear(288, 500)\n",
    "        \n",
    "        # linear layer (500 -> 250)\n",
    "        self.fc2 = nn.Linear(500, 250)\n",
    "        \n",
    "        # linear layer (250 -> 125)\n",
    "        self.fc3 = nn.Linear(250, 125)\n",
    "        \n",
    "        # linear layer (125 -> 1)\n",
    "        self.fc4 = nn.Linear(125, 755001)\n",
    "        \n",
    "        # dropout layer (p=0.25)\n",
    "        self.dropout = nn.Dropout(0.175)\n",
    "        \n",
    "        # LogSoftmax\n",
    "        self.LSM = nn.LogSoftmax()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \n",
    "        # add 1st hidden layer, with relu activation function\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h2\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h3\n",
    "        x = self.fc3(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        #h4\n",
    "        x = self.fc4(x)\n",
    "        x = self.LSM(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "#-#-# You do NOT have to modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_HR = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_patho.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=288, out_features=500, bias=True)\n",
       "  (fc2): Linear(in_features=500, out_features=250, bias=True)\n",
       "  (fc3): Linear(in_features=250, out_features=125, bias=True)\n",
       "  (fc4): Linear(in_features=125, out_features=755001, bias=True)\n",
       "  (dropout): Dropout(p=0.175, inplace=False)\n",
       "  (LSM): LogSoftmax()\n",
       ")"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_HR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO: select loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "### TODO: select optimizer\n",
    "optimizer = optim.SGD(model_HR.parameters(), lr=0.01, momentum = 0.9)\n",
    "\n",
    "VERSION = 'Test_version'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    time_start = time.time()\n",
    "    train_class = []\n",
    "    valid_class = []\n",
    "    epoch_class = []\n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        LR = 0.01\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        model.train()\n",
    "        for idx, (data, target) in enumerate(loaders['train']):\n",
    "            \n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(data)\n",
    "            \n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        model.eval()\n",
    "        for idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            ## update the average validation loss\n",
    "            output = model(data)\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(output, target.squeeze(-1))\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "            \n",
    "        # calculate average losses\n",
    "        train_loss = train_loss/len(loaders['train'].sampler)\n",
    "        \n",
    "        \n",
    "        valid_loss = valid_loss/len(loaders['valid'].sampler)\n",
    "        \n",
    "        if valid_loss < 0.35 and valid_loss > 0.15:\n",
    "            LR=0.005\n",
    "        elif valid_loss < 0.15:\n",
    "            LR=0.001\n",
    "        \n",
    "        \n",
    "        # Calcul time\n",
    "        time_now = time.time()\n",
    "        \n",
    "        time_epoch = (time_now - time_start)/60\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f} \\tTime since the beginning {:.1f} min \\tLearning rate: {:.6f} '.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss,\n",
    "            time_epoch,\n",
    "            LR\n",
    "            ))\n",
    "        \n",
    "        ## TODO: save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss,\n",
    "            torch.save(model.state_dict(), VERSION))\n",
    "                 )\n",
    "            valid_loss_min = valid_loss\n",
    "        \n",
    "        # store class data\n",
    "        train_class.append(train_loss)\n",
    "        valid_class.append(valid_loss)\n",
    "        epoch_class.append(epoch)\n",
    "    \n",
    "    plt.plot(epoch_class, train_class, 'g', label='Training loss')\n",
    "    plt.plot(epoch_class, valid_class, 'b', label='validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amallet\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: 13.518797 \tValidation Loss: 13.482560 \tTime since the beginning 2.0 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (inf --> 13.482560).  Saving model ...\n",
      "Epoch: 2 \tTraining Loss: 12.993568 \tValidation Loss: 11.360754 \tTime since the beginning 3.9 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (13.482560 --> 11.360754).  Saving model ...\n",
      "Epoch: 3 \tTraining Loss: 10.173163 \tValidation Loss: 9.870750 \tTime since the beginning 6.0 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (11.360754 --> 9.870750).  Saving model ...\n",
      "Epoch: 4 \tTraining Loss: 8.880490 \tValidation Loss: 9.396496 \tTime since the beginning 7.9 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.870750 --> 9.396496).  Saving model ...\n",
      "Epoch: 5 \tTraining Loss: 7.911295 \tValidation Loss: 9.231639 \tTime since the beginning 9.8 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.396496 --> 9.231639).  Saving model ...\n",
      "Epoch: 6 \tTraining Loss: 7.266767 \tValidation Loss: 9.220892 \tTime since the beginning 11.8 min \tLearning rate: 0.010000 \n",
      "Validation loss decreased (9.231639 --> 9.220892).  Saving model ...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_res = train(6, data_loader, model_HR, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_iter\n",
      " <torch.utils.data.dataloader._SingleProcessDataLoaderIter object at 0x0000017425C95DC8>\n",
      "image test data tensor([[-8.7347e-01,  4.5810e-01,  1.8434e-01,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        [-8.7347e-01,  5.0093e-01,  5.1970e-01,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        [ 6.7320e-02,  2.0108e-01,  4.6429e-01,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        ...,\n",
      "        [ 6.7320e-02, -2.7011e-01, -2.2393e-01,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        [-8.7347e-01,  6.7228e-01,  9.9986e-04,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00],\n",
      "        [-8.7347e-01,  2.9737e-02, -2.2418e-01,  ...,  0.0000e+00,\n",
      "          1.0000e+00,  0.0000e+00]])\n",
      "tensor([[ 0.0000e+00],\n",
      "        [4.9407e-324],\n",
      "        [9.8813e-324],\n",
      "        [1.4822e-323],\n",
      "        [1.9763e-323],\n",
      "        [2.4703e-323],\n",
      "        [2.9644e-323],\n",
      "        [3.4585e-323],\n",
      "        [3.9525e-323],\n",
      "        [4.4466e-323]], dtype=torch.float64)\n",
      "Result preditcion model on dataset:\n",
      " tensor([[-16.5751, -17.0310, -15.6306,  ..., -17.8134, -17.3026,  -9.7491],\n",
      "        [-16.3610, -16.4818, -15.7571,  ..., -17.5661, -16.9187,  -8.6153],\n",
      "        [-16.6982, -16.3316, -16.4984,  ..., -18.0041, -17.4494,  -6.7967],\n",
      "        ...,\n",
      "        [-16.5014, -16.2826, -16.3041,  ..., -17.9160, -17.3325,  -6.9546],\n",
      "        [-16.7769, -16.5496, -16.4852,  ..., -18.0374, -17.6308,  -7.3342],\n",
      "        [-17.9808, -18.3351, -16.9502,  ..., -19.2906, -18.7205, -10.2852]],\n",
      "       grad_fn=<LogSoftmaxBackward>)\n",
      "\n",
      "probs\n",
      " tensor([[6.3320e-08, 4.0137e-08, 1.6282e-07,  ..., 1.8355e-08, 3.0588e-08,\n",
      "         5.8348e-05],\n",
      "        [7.8432e-08, 6.9511e-08, 1.4348e-07,  ..., 2.3504e-08, 4.4904e-08,\n",
      "         1.8132e-04],\n",
      "        [5.5987e-08, 8.0773e-08, 6.8367e-08,  ..., 1.5167e-08, 2.6414e-08,\n",
      "         1.1174e-03],\n",
      "        ...,\n",
      "        [6.8163e-08, 8.4834e-08, 8.3028e-08,  ..., 1.6565e-08, 2.9689e-08,\n",
      "         9.5424e-04],\n",
      "        [5.1745e-08, 6.4953e-08, 6.9277e-08,  ..., 1.4671e-08, 2.2030e-08,\n",
      "         6.5285e-04],\n",
      "        [1.5525e-08, 1.0893e-08, 4.3513e-08,  ..., 4.1899e-09, 7.4096e-09,\n",
      "         3.4133e-05]], grad_fn=<ExpBackward>)\n",
      "tensor(0.1894, grad_fn=<MaxBackward1>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\amallet\\Anaconda\\envs\\udacity_env\\lib\\site-packages\\ipykernel_launcher.py:44: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "dataiter_test = iter(data_loader['test'])\n",
    "print('data_iter\\n',dataiter_test)\n",
    "data_test = dataiter_test.next()\n",
    "data_test_data = data_test[0]\n",
    "print('image test data',data_test_data)\n",
    "data_test_label = data_test[1]\n",
    "print(data_test_label)\n",
    "\n",
    "model_test = model_HR\n",
    "model_test.load_state_dict(torch.load(VERSION))\n",
    "model_test = model_test.eval()\n",
    "\n",
    "\n",
    "out_fwd = model_test.forward(data_test_data)\n",
    "print('Result preditcion model on dataset:\\n {}\\n'.format(out_fwd))\n",
    "probs = torch.exp(out_fwd)\n",
    "print('probs\\n', probs)\n",
    "print(probs.max())\n",
    "print(probs.mi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
